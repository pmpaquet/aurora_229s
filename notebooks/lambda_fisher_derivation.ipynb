{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch einops numpy timm==0.6.13 scipy gcsfs cdsapi xarray zarr netcdf4 matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /workspace/aurora_229s\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aurora import inference_helper\n",
    "from aurora.model import aurora, swin3d\n",
    "\n",
    "def reload():\n",
    "    importlib.reload(inference_helper)\n",
    "    importlib.reload(aurora)\n",
    "    importlib.reload(swin3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_mem(msg):\n",
    "    print(f'{msg}:')\n",
    "    print(\"\\ttorch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "    print(\"\\ttorch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "    print(\"\\ttorch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "    print()\n",
    "\n",
    "def print_timestamp():\n",
    "    current_time = datetime.datetime.now()\n",
    "    formatted_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(formatted_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable names\n",
    "surf_vars_names = [\n",
    "    ('2t', '2m_temperature'),\n",
    "    ('10u', '10m_u_component_of_wind'),\n",
    "    ('10v', '10m_v_component_of_wind'),\n",
    "    ('msl', 'mean_sea_level_pressure'),\n",
    "]\n",
    "static_vars_names = [\n",
    "    ('z', 'z'),\n",
    "    ('slt', 'slt'),\n",
    "    ('lsm', 'lsm')\n",
    "]\n",
    "atmos_vars_names = [\n",
    "    ('t', 'temperature'),\n",
    "    ('u', 'u_component_of_wind'),\n",
    "    ('v', 'v_component_of_wind'),\n",
    "    ('q', 'specific_humidity'),\n",
    "    ('z', 'geopotential')\n",
    "]\n",
    "\n",
    "all_vars_names = surf_vars_names + atmos_vars_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = aurora.Aurora()\n",
    "model.load_checkpoint(\"microsoft/aurora\", \"aurora-0.25-finetuned.ckpt\")\n",
    "# model.load_checkpoint_local(\n",
    "#     \"/workspace/models/hf_ckpt/aurora-0.25-finetuned.ckpt\"\n",
    "# )\n",
    "model.configure_activation_checkpointing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save May for testing\n",
    "# base_date_list = [\"2022-02-01\", \"2022-04-01\", \"2022-05-01\", \"2022-07-01\", \"2022-11-01\"]\n",
    "base_date_list = [\"2022-02-01\", \"2022-04-01\", \"2022-07-01\", \"2022-11-01\"]\n",
    "\n",
    "base_save_dir = Path(\"/workspace/models/fisher\")\n",
    "base_save_dir.mkdir(exist_ok=True, parents=True)\n",
    "device = 'cuda'\n",
    "\n",
    "model.train()\n",
    "model = model.to(device)\n",
    "\n",
    "# MAJOR LOOP -- SURF VARS\n",
    "for sh_var,lh_var in all_vars_names:\n",
    "    print(sh_var, lh_var)\n",
    "    print_timestamp()\n",
    "    print('\\n')\n",
    "\n",
    "    cnt = 0\n",
    "    mae_losses = []\n",
    "    grads = {}\n",
    "    batcher = inference_helper.InferenceBatcher(\n",
    "        base_date_list=base_date_list,\n",
    "        data_path=Path(\"/workspace/data\"),\n",
    "        max_n_days=14,\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        model.zero_grad() # Critical to zero-out gradients\n",
    "        batch, labels = batcher.get_batch()\n",
    "        if batch is None or labels is None:\n",
    "            break\n",
    "        print(batcher.day, batcher.time_idx - 1)\n",
    "\n",
    "        p = next(model.parameters())\n",
    "        batch = batch.type(p.dtype)\n",
    "        batch = batch.crop(model.patch_size)\n",
    "        batch = batch.to(p.device)\n",
    "\n",
    "        labels = labels.type(p.dtype)\n",
    "        labels = labels.crop(model.patch_size)\n",
    "\n",
    "        # preds = model.forward(batch)\n",
    "        preds = torch.utils.checkpoint.checkpoint(model.forward, batch, use_reentrant=False)\n",
    "\n",
    "        if (sh_var,lh_var) in surf_vars_names:\n",
    "            task_pred = preds.surf_vars[sh_var][0, 0]\n",
    "            ref = labels.surf_vars[sh_var][0,0].to(device)\n",
    "        else:\n",
    "            task_pred = preds.atmos_vars[sh_var][0, 0]\n",
    "            ref = labels.atmos_vars[sh_var][0,0].to(device)\n",
    "\n",
    "        # Paper uses mean absolute error\n",
    "        loss = torch.mean(torch.abs(task_pred - ref))\n",
    "        # loss = torch.utils.checkpoint.checkpoint(loss_fn, ref, task_pred, use_reentrant=False)\n",
    "        loss.backward()\n",
    "\n",
    "        for name,param in model.named_parameters():\n",
    "            if cnt == 0:\n",
    "                grads[name] = torch.square(param.grad.clone().to('cpu'))\n",
    "            else:\n",
    "                grads[name] += torch.swaure(param.grad.clone().to('cpu'))\n",
    "\n",
    "        cnt += 1\n",
    "        mae_losses.append(loss.clone().detach().to('cpu').numpy())\n",
    "        del preds, task_pred, ref, batch, labels, loss\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # finished with loop\n",
    "    task_dir = base_save_dir / lh_var\n",
    "    task_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for name,param in grads.items():\n",
    "        torch.save(param / float(cnt), task_dir / f'{name}.pt')\n",
    "    np.save(task_dir / f'LOSSES.npy', np.array(mae_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Save May and August for testing\n",
    "base_date_list = [\"2022-02-01\", \"2022-04-01\", \"2022-07-01\", \"2022-11-01\"]\n",
    "\n",
    "base_save_dir = Path(\"/workspace/models/fisher\")\n",
    "base_save_dir.mkdir(exist_ok=True, parents=True)\n",
    "# device = xm.xla_device()\n",
    "device = 'cuda'\n",
    "\n",
    "bdl_model = inference_helper.BackboneDecoderLayers(model.backbone.decoder_layers, model.backbone.num_decoder_layers)\n",
    "bdl_model = bdl_model.to(device)\n",
    "decoder = model.decoder.to(device)\n",
    "decoder.eval()\n",
    "\n",
    "# MAJOR LOOP -- SURF VARS\n",
    "for sh_var,lh_var in all_vars_names:\n",
    "    print(sh_var, lh_var)\n",
    "    print_timestamp()\n",
    "    print('\\n')\n",
    "\n",
    "    cnt = 0\n",
    "    mae_losses = []\n",
    "    grads = {}\n",
    "    batcher = inference_helper.InferenceBatcher(base_date_list=base_date_list, data_path=download_path)\n",
    "\n",
    "    while True:\n",
    "        model.zero_grad() # Critical to zero-out gradients\n",
    "        batch, labels = batcher.get_batch()\n",
    "        if batch is None or labels is None:\n",
    "            break\n",
    "        print(batcher.day, batcher.time_idx - 1)\n",
    "\n",
    "        rollout_step = batch.metadata.rollout_step\n",
    "        batch = inference_helper.preprocess_batch(model=model, batch=batch, device=device)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        p = next(model.parameters())\n",
    "        labels = labels.type(p.dtype)\n",
    "        labels = labels.crop(model.patch_size)\n",
    "\n",
    "        # -------------------------------------\n",
    "        # 2. Encoder Forward\n",
    "        with torch.no_grad():\n",
    "            x, patch_res = inference_helper.encoder_forward(model=model, batch=batch, device=device)\n",
    "        batch = batch.to('cpu')\n",
    "        torch.cuda.empty_cache()\n",
    "        # gpu_mem('ENCODER FWD PASS')\n",
    "\n",
    "        # 3. Backbone encoder layers forward\n",
    "        with torch.no_grad():\n",
    "            x, skips, c, all_enc_res, padded_outs = inference_helper.backbone_encoder_layers_forward(\n",
    "                model=model, x=x, patch_res=patch_res, rollout_step=rollout_step, device=device,\n",
    "            )\n",
    "        torch.cuda.empty_cache()\n",
    "        # gpu_mem('BACKBONE ENCODER FWD PASS')\n",
    "\n",
    "        # 6. BDL forward pass\n",
    "        x = bdl_model.forward(\n",
    "            x=x, skips=skips, c=c, all_enc_res=all_enc_res, padded_outs=padded_outs, rollout_step=rollout_step,\n",
    "        )\n",
    "        del skips, c, all_enc_res\n",
    "        torch.cuda.empty_cache()\n",
    "        # gpu_mem('BDL forward pass')\n",
    "\n",
    "        # 7. Decoder forward pass\n",
    "        preds = inference_helper.decoder_forward(\n",
    "            decoder=decoder, x=x, batch=batch, patch_res=patch_res, surf_stats=model.surf_stats,\n",
    "        )\n",
    "        del x, batch, patch_res\n",
    "\n",
    "        # -------------------------------------\n",
    "\n",
    "\n",
    "        if (sh_var,lh_var) in surf_vars_names:\n",
    "            task_pred = preds.surf_vars[sh_var][0, 0]\n",
    "            ref = labels.surf_vars[sh_var][0,0].to(device)\n",
    "        else:\n",
    "            task_pred = preds.atmos_vars[sh_var][0, 0]\n",
    "            ref = labels.atmos_vars[sh_var][0,0].to(device)\n",
    "\n",
    "        # Paper uses mean absolute error\n",
    "        loss = torch.mean(torch.abs(task_pred - ref))\n",
    "        # loss = torch.utils.checkpoint.checkpoint(loss_fn, ref, task_pred, use_reentrant=False)\n",
    "        loss.backward()\n",
    "\n",
    "        for name,param in model.named_parameters():\n",
    "            if cnt == 0:\n",
    "            grads[name] = torch.square(param.grad.clone().to('cpu'))\n",
    "            else:\n",
    "            grads[name] += torch.swaure(param.grad.clone().to('cpu'))\n",
    "\n",
    "        cnt += 1\n",
    "        mae_losses.append(loss.clone().detach().to('cpu').numpy())\n",
    "        del preds, task_pred, ref, batch, labels, skips, c, all_enc_res, padded_outs, patch_res\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # finished with loop\n",
    "    task_dir = base_save_dir / lh_var\n",
    "    task_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for name,param in grads.items():\n",
    "    torch.save(param / float(cnt), task_dir / f'{name}.pt')\n",
    "    np.save(task_dir / f'LOSSES.npy', np.array(mae_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "from aurora.download_data import download_for_day\n",
    "\n",
    "# Save May and August for testing\n",
    "base_date_list = [\"2022-02-01\", \"2022-04-01\", \"2022-07-01\", \"2022-11-01\"]\n",
    "base_date_list = [\"2022-02-01\", \"2022-04-01\"]#, \"2022-07-01\", \"2022-11-01\"]\n",
    "\n",
    "base_save_dir = Path(\"/workspace/models/fisher\")\n",
    "base_save_dir.mkdir(exist_ok=True, parents=True)\n",
    "# device = xm.xla_device()\n",
    "device = 'cuda'\n",
    "\n",
    "bel_model = inference_helper.BackboneEncoderLayers(model.backbone.encoder_layers)\n",
    "bel_model = bel_model.to(device)\n",
    "bdl_model = inference_helper.BackboneDecoderLayers(model.backbone.decoder_layers, model.backbone.num_decoder_layers)\n",
    "bdl_model = bdl_model.to(device)\n",
    "decoder = model.decoder.to(device)\n",
    "decoder.eval()\n",
    "\n",
    "# MAJOR LOOP -- SURF VARS\n",
    "for sh_var,lh_var in all_vars_names:\n",
    "    print(sh_var, lh_var)\n",
    "    print_timestamp()\n",
    "    print('\\n')\n",
    "\n",
    "    cnt = 0\n",
    "    mae_losses = []\n",
    "    grads = {'backbone_encoder':{}, 'backbone_decoder':[]}\n",
    "    download_for_day(day=base_date_list[0], download_path=Path(\"/workspace/data\"))\n",
    "    batcher = inference_helper.InferenceBatcher(\n",
    "        base_date_list=base_date_list,\n",
    "        data_path=Path(\"/workspace/data\"),\n",
    "        max_n_days=3\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        model.zero_grad() # Critical to zero-out gradients\n",
    "        try:\n",
    "            batch, labels = batcher.get_batch()\n",
    "        except:\n",
    "            break\n",
    "        if batch is None or labels is None:\n",
    "            break\n",
    "        print(batcher.day, batcher.time_idx - 1)\n",
    "\n",
    "        rollout_step = batch.metadata.rollout_step\n",
    "        batch = inference_helper.preprocess_batch(model=model, batch=batch, device=device)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        p = next(model.parameters())\n",
    "        labels = labels.type(p.dtype)\n",
    "        labels = labels.crop(model.patch_size)\n",
    "\n",
    "        # -------------------------------------\n",
    "        # 2. Encoder Forward\n",
    "        with torch.no_grad():\n",
    "            x, patch_res = inference_helper.encoder_forward(model=model, batch=batch, device=device)\n",
    "        batch = batch.to('cpu')\n",
    "        torch.cuda.empty_cache()\n",
    "        # gpu_mem('ENCODER FWD PASS')\n",
    "\n",
    "        # 3. Backbone encoder layers forward\n",
    "        with torch.no_grad():\n",
    "            c, all_enc_res, padded_outs = inference_helper.backbone_prep(model=model, x=x, patch_res=patch_res, device=device)\n",
    "            # x, skips, c, all_enc_res, padded_outs = inference_helper.backbone_encoder_layers_forward(\n",
    "            #     model=model, x=x, patch_res=patch_res, rollout_step=rollout_step, device=device,\n",
    "            # )\n",
    "        torch.cuda.empty_cache()\n",
    "        # gpu_mem('BACKBONE ENCODER FWD PASS')\n",
    "\n",
    "        # Step 4?\n",
    "        x, skips = bel_model.forward(x=x, c=c, all_enc_res=all_enc_res, rollout_step=rollout_step)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # 6. BDL forward pass\n",
    "        x = bdl_model.forward(\n",
    "            x=x, skips=skips, c=c, all_enc_res=all_enc_res, padded_outs=padded_outs, rollout_step=rollout_step,\n",
    "        )\n",
    "        del skips, c, all_enc_res, padded_outs\n",
    "        torch.cuda.empty_cache()\n",
    "        # gpu_mem('BDL forward pass')\n",
    "\n",
    "        # 7. Decoder forward pass\n",
    "        preds = inference_helper.decoder_forward(\n",
    "            decoder=decoder, x=x, batch=batch, patch_res=patch_res, surf_stats=model.surf_stats,\n",
    "        )\n",
    "        del x, batch, patch_res\n",
    "\n",
    "        # -------------------------------------\n",
    "\n",
    "\n",
    "        if (sh_var,lh_var) in surf_vars_names:\n",
    "            task_pred = preds.surf_vars[sh_var][0, 0]\n",
    "            ref = labels.surf_vars[sh_var][0,0].to(device)\n",
    "        else:\n",
    "            task_pred = preds.atmos_vars[sh_var][0, 0]\n",
    "            ref = labels.atmos_vars[sh_var][0,0].to(device)\n",
    "\n",
    "        # Paper uses mean absolute error\n",
    "        loss = torch.mean(torch.abs(task_pred - ref))\n",
    "        # loss = torch.utils.checkpoint.checkpoint(loss_fn, ref, task_pred, use_reentrant=False)\n",
    "        loss.backward()\n",
    "\n",
    "        for name,param in model.named_parameters():\n",
    "            if cnt == 0:\n",
    "                grads[name] = torch.square(param.grad.clone().to('cpu'))\n",
    "            else:\n",
    "                grads[name] += torch.square(param.grad.clone().to('cpu'))\n",
    "\n",
    "        cnt += 1\n",
    "        mae_losses.append(loss.clone().detach().to('cpu').numpy())\n",
    "        del preds, task_pred, ref\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # finished with loop\n",
    "    task_dir = base_save_dir / lh_var\n",
    "    task_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for name,param in grads.items():\n",
    "        torch.save(param / float(cnt), task_dir / f'{name}.pt')\n",
    "    np.save(task_dir / f'LOSSES.npy', np.array(mae_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
