{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch einops numpy timm==0.6.13 scipy gcsfs cdsapi xarray zarr netcdf4 matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /workspace/aurora_229s\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aurora import inference_helper\n",
    "from aurora.model import aurora, swin3d\n",
    "\n",
    "def reload():\n",
    "    importlib.reload(inference_helper)\n",
    "    importlib.reload(aurora)\n",
    "    importlib.reload(swin3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_mem(msg):\n",
    "    print(f'{msg}:')\n",
    "    print(\"\\ttorch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "    print(\"\\ttorch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "    print(\"\\ttorch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "    print()\n",
    "\n",
    "def print_timestamp():\n",
    "    current_time = datetime.datetime.now()\n",
    "    formatted_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(formatted_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable names\n",
    "surf_vars_names = [\n",
    "    ('2t', '2m_temperature'),\n",
    "    ('10u', '10m_u_component_of_wind'),\n",
    "    ('10v', '10m_v_component_of_wind'),\n",
    "    ('msl', 'mean_sea_level_pressure'),\n",
    "]\n",
    "static_vars_names = [\n",
    "    ('z', 'z'),\n",
    "    ('slt', 'slt'),\n",
    "    ('lsm', 'lsm')\n",
    "]\n",
    "atmos_vars_names = [\n",
    "    ('t', 'temperature'),\n",
    "    ('u', 'u_component_of_wind'),\n",
    "    ('v', 'v_component_of_wind'),\n",
    "    ('q', 'specific_humidity'),\n",
    "    ('z', 'geopotential')\n",
    "]\n",
    "\n",
    "all_vars_names = surf_vars_names + atmos_vars_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = aurora.Aurora()\n",
    "# model.load_checkpoint(\"microsoft/aurora\", \"aurora-0.25-finetuned.ckpt\")\n",
    "model.load_checkpoint_local(\n",
    "    \"/workspace/models/hf_ckpt/aurora-0.25-finetuned.ckpt\"\n",
    ")\n",
    "model.configure_activation_checkpointing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save May for testing\n",
    "# base_date_list = [\"2022-02-01\", \"2022-04-01\", \"2022-05-01\", \"2022-07-01\", \"2022-11-01\"]\n",
    "base_date_list = [\"2022-02-01\", \"2022-04-01\", \"2022-07-01\", \"2022-11-01\"]\n",
    "\n",
    "base_save_dir = Path(\"/workspace/models/fisher\")\n",
    "base_save_dir.mkdir(exist_ok=True, parents=True)\n",
    "device = 'cuda'\n",
    "\n",
    "model.train()\n",
    "model = model.to(device)\n",
    "\n",
    "# MAJOR LOOP -- SURF VARS\n",
    "for sh_var,lh_var in all_vars_names:\n",
    "    print(sh_var, lh_var)\n",
    "    print_timestamp()\n",
    "    print('\\n')\n",
    "\n",
    "    cnt = 0\n",
    "    mae_losses = []\n",
    "    grads = {}\n",
    "    batcher = inference_helper.InferenceBatcher(\n",
    "        base_date_list=base_date_list,\n",
    "        data_path=Path(\"/workspace/data\"),\n",
    "        max_n_days=14,\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        model.zero_grad() # Critical to zero-out gradients\n",
    "        batch, labels = batcher.get_batch()\n",
    "        if batch is None or labels is None:\n",
    "            break\n",
    "        print(batcher.day, batcher.time_idx - 1)\n",
    "\n",
    "        p = next(model.parameters())\n",
    "        batch = batch.type(p.dtype)\n",
    "        batch = batch.crop(model.patch_size)\n",
    "        batch = batch.to(p.device)\n",
    "\n",
    "        labels = labels.type(p.dtype)\n",
    "        labels = labels.crop(model.patch_size)\n",
    "\n",
    "        # preds = model.forward(batch)\n",
    "        preds = torch.utils.checkpoint.checkpoint(model.forward, batch, use_reentrant=False)\n",
    "\n",
    "        if (sh_var,lh_var) in surf_vars_names:\n",
    "            task_pred = preds.surf_vars[sh_var][0, 0]\n",
    "            ref = labels.surf_vars[sh_var][0,0].to(device)\n",
    "        else:\n",
    "            task_pred = preds.atmos_vars[sh_var][0, 0]\n",
    "            ref = labels.atmos_vars[sh_var][0,0].to(device)\n",
    "\n",
    "        # Paper uses mean absolute error\n",
    "        loss = torch.mean(torch.abs(task_pred - ref))\n",
    "        # loss = torch.utils.checkpoint.checkpoint(loss_fn, ref, task_pred, use_reentrant=False)\n",
    "        loss.backward()\n",
    "\n",
    "        for name,param in model.named_parameters():\n",
    "            if cnt == 0:\n",
    "                grads[name] = torch.square(param.grad.clone().to('cpu'))\n",
    "            else:\n",
    "                grads[name] += torch.swaure(param.grad.clone().to('cpu'))\n",
    "\n",
    "        cnt += 1\n",
    "        mae_losses.append(loss.clone().detach().to('cpu').numpy())\n",
    "        del preds, task_pred, ref, batch, labels, loss\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # finished with loop\n",
    "    task_dir = base_save_dir / lh_var\n",
    "    task_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for name,param in grads.items():\n",
    "        torch.save(param / float(cnt), task_dir / f'{name}.pt')\n",
    "    np.save(task_dir / f'LOSSES.npy', np.array(mae_losses))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
