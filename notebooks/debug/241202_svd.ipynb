{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "297b9106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4824be34-060d-422a-addf-841c2c3609b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmpaquet/Projects/Stanford/CS229S/Project/Project_aurora/aurora_229s/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from aurora import Aurora\n",
    "\n",
    "model = Aurora()\n",
    "# model.load_checkpoint(\"microsoft/aurora\", \"aurora-0.25-finetuned.ckpt\")\n",
    "model.load_checkpoint_local(\n",
    "    \"/Users/pmpaquet/Projects/Stanford/CS229S/Project/Project_aurora/models/hf_ckpt/aurora-0.25-finetuned.ckpt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ef5c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_param(name, param):\n",
    "    if len(param.shape) <= 1:\n",
    "        return False\n",
    "    elif 'lora' in name:\n",
    "        return False\n",
    "    elif not (name.startswith('backbone.encoder_layers') or name.startswith('backbone.decoder_layers')):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db7eb2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.atmos_latents                                            -- torch.Size([3, 512])\n",
      "encoder.surf_level_encoding                                      -- torch.Size([512])\n",
      "encoder.surf_mlp.net.0.weight                                    -- torch.Size([2048, 512])\n",
      "encoder.surf_mlp.net.0.bias                                      -- torch.Size([2048])\n",
      "encoder.surf_mlp.net.2.weight                                    -- torch.Size([512, 2048])\n",
      "encoder.surf_mlp.net.2.bias                                      -- torch.Size([512])\n",
      "encoder.surf_norm.weight                                         -- torch.Size([512])\n",
      "encoder.surf_norm.bias                                           -- torch.Size([512])\n",
      "encoder.pos_embed.weight                                         -- torch.Size([512, 512])\n",
      "encoder.pos_embed.bias                                           -- torch.Size([512])\n",
      "encoder.scale_embed.weight                                       -- torch.Size([512, 512])\n",
      "encoder.scale_embed.bias                                         -- torch.Size([512])\n",
      "encoder.lead_time_embed.weight                                   -- torch.Size([512, 512])\n",
      "encoder.lead_time_embed.bias                                     -- torch.Size([512])\n",
      "encoder.absolute_time_embed.weight                               -- torch.Size([512, 512])\n",
      "encoder.absolute_time_embed.bias                                 -- torch.Size([512])\n",
      "encoder.atmos_levels_embed.weight                                -- torch.Size([512, 512])\n",
      "encoder.atmos_levels_embed.bias                                  -- torch.Size([512])\n",
      "encoder.surf_token_embeds.bias                                   -- torch.Size([512])\n",
      "encoder.surf_token_embeds.weights.10u                            -- torch.Size([512, 1, 2, 4, 4])\n",
      "encoder.surf_token_embeds.weights.10v                            -- torch.Size([512, 1, 2, 4, 4])\n",
      "encoder.surf_token_embeds.weights.2t                             -- torch.Size([512, 1, 2, 4, 4])\n",
      "encoder.surf_token_embeds.weights.lsm                            -- torch.Size([512, 1, 2, 4, 4])\n",
      "encoder.surf_token_embeds.weights.msl                            -- torch.Size([512, 1, 2, 4, 4])\n",
      "encoder.surf_token_embeds.weights.slt                            -- torch.Size([512, 1, 2, 4, 4])\n",
      "encoder.surf_token_embeds.weights.z                              -- torch.Size([512, 1, 2, 4, 4])\n",
      "encoder.atmos_token_embeds.bias                                  -- torch.Size([512])\n",
      "encoder.atmos_token_embeds.weights.q                             -- torch.Size([512, 1, 2, 4, 4])\n",
      "encoder.atmos_token_embeds.weights.t                             -- torch.Size([512, 1, 2, 4, 4])\n",
      "encoder.atmos_token_embeds.weights.u                             -- torch.Size([512, 1, 2, 4, 4])\n",
      "encoder.atmos_token_embeds.weights.v                             -- torch.Size([512, 1, 2, 4, 4])\n",
      "encoder.atmos_token_embeds.weights.z                             -- torch.Size([512, 1, 2, 4, 4])\n",
      "encoder.level_agg.layers.0.0.to_q.weight                         -- torch.Size([512, 512])\n",
      "encoder.level_agg.layers.0.0.to_kv.weight                        -- torch.Size([1024, 512])\n",
      "encoder.level_agg.layers.0.0.to_out.weight                       -- torch.Size([512, 512])\n",
      "encoder.level_agg.layers.0.1.net.0.weight                        -- torch.Size([2048, 512])\n",
      "encoder.level_agg.layers.0.1.net.0.bias                          -- torch.Size([2048])\n",
      "encoder.level_agg.layers.0.1.net.2.weight                        -- torch.Size([512, 2048])\n",
      "encoder.level_agg.layers.0.1.net.2.bias                          -- torch.Size([512])\n",
      "encoder.level_agg.layers.0.2.weight                              -- torch.Size([512])\n",
      "encoder.level_agg.layers.0.2.bias                                -- torch.Size([512])\n",
      "encoder.level_agg.layers.0.3.weight                              -- torch.Size([512])\n",
      "encoder.level_agg.layers.0.3.bias                                -- torch.Size([512])\n",
      "backbone.time_mlp.0.weight                                       -- torch.Size([512, 512])\n",
      "backbone.time_mlp.0.bias                                         -- torch.Size([512])\n",
      "backbone.time_mlp.2.weight                                       -- torch.Size([512, 512])\n",
      "backbone.time_mlp.2.bias                                         -- torch.Size([512])\n",
      "backbone.encoder_layers.0.blocks.0.norm1.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.encoder_layers.0.blocks.0.norm1.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.encoder_layers.0.blocks.0.attn.qkv.weight               -- torch.Size([1536, 512])\n",
      "backbone.encoder_layers.0.blocks.0.attn.qkv.bias                 -- torch.Size([1536])\n",
      "backbone.encoder_layers.0.blocks.0.attn.proj.weight              -- torch.Size([512, 512])\n",
      "backbone.encoder_layers.0.blocks.0.attn.proj.bias                -- torch.Size([512])\n",
      "backbone.encoder_layers.0.blocks.0.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 512])\n",
      "backbone.encoder_layers.0.blocks.0.attn.lora_proj.loras.0.lora_B -- torch.Size([512, 8])\n",
      "backbone.encoder_layers.0.blocks.0.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 512])\n",
      "backbone.encoder_layers.0.blocks.0.attn.lora_qkv.loras.0.lora_B  -- torch.Size([1536, 8])\n",
      "backbone.encoder_layers.0.blocks.0.norm2.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.encoder_layers.0.blocks.0.norm2.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.encoder_layers.0.blocks.0.mlp.fc1.weight                -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.0.blocks.0.mlp.fc1.bias                  -- torch.Size([2048])\n",
      "backbone.encoder_layers.0.blocks.0.mlp.fc2.weight                -- torch.Size([512, 2048])\n",
      "backbone.encoder_layers.0.blocks.0.mlp.fc2.bias                  -- torch.Size([512])\n",
      "backbone.encoder_layers.0.blocks.1.norm1.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.encoder_layers.0.blocks.1.norm1.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.encoder_layers.0.blocks.1.attn.qkv.weight               -- torch.Size([1536, 512])\n",
      "backbone.encoder_layers.0.blocks.1.attn.qkv.bias                 -- torch.Size([1536])\n",
      "backbone.encoder_layers.0.blocks.1.attn.proj.weight              -- torch.Size([512, 512])\n",
      "backbone.encoder_layers.0.blocks.1.attn.proj.bias                -- torch.Size([512])\n",
      "backbone.encoder_layers.0.blocks.1.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 512])\n",
      "backbone.encoder_layers.0.blocks.1.attn.lora_proj.loras.0.lora_B -- torch.Size([512, 8])\n",
      "backbone.encoder_layers.0.blocks.1.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 512])\n",
      "backbone.encoder_layers.0.blocks.1.attn.lora_qkv.loras.0.lora_B  -- torch.Size([1536, 8])\n",
      "backbone.encoder_layers.0.blocks.1.norm2.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.encoder_layers.0.blocks.1.norm2.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.encoder_layers.0.blocks.1.mlp.fc1.weight                -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.0.blocks.1.mlp.fc1.bias                  -- torch.Size([2048])\n",
      "backbone.encoder_layers.0.blocks.1.mlp.fc2.weight                -- torch.Size([512, 2048])\n",
      "backbone.encoder_layers.0.blocks.1.mlp.fc2.bias                  -- torch.Size([512])\n",
      "backbone.encoder_layers.0.blocks.2.norm1.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.encoder_layers.0.blocks.2.norm1.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.encoder_layers.0.blocks.2.attn.qkv.weight               -- torch.Size([1536, 512])\n",
      "backbone.encoder_layers.0.blocks.2.attn.qkv.bias                 -- torch.Size([1536])\n",
      "backbone.encoder_layers.0.blocks.2.attn.proj.weight              -- torch.Size([512, 512])\n",
      "backbone.encoder_layers.0.blocks.2.attn.proj.bias                -- torch.Size([512])\n",
      "backbone.encoder_layers.0.blocks.2.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 512])\n",
      "backbone.encoder_layers.0.blocks.2.attn.lora_proj.loras.0.lora_B -- torch.Size([512, 8])\n",
      "backbone.encoder_layers.0.blocks.2.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 512])\n",
      "backbone.encoder_layers.0.blocks.2.attn.lora_qkv.loras.0.lora_B  -- torch.Size([1536, 8])\n",
      "backbone.encoder_layers.0.blocks.2.norm2.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.encoder_layers.0.blocks.2.norm2.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.encoder_layers.0.blocks.2.mlp.fc1.weight                -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.0.blocks.2.mlp.fc1.bias                  -- torch.Size([2048])\n",
      "backbone.encoder_layers.0.blocks.2.mlp.fc2.weight                -- torch.Size([512, 2048])\n",
      "backbone.encoder_layers.0.blocks.2.mlp.fc2.bias                  -- torch.Size([512])\n",
      "backbone.encoder_layers.0.blocks.3.norm1.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.encoder_layers.0.blocks.3.norm1.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.encoder_layers.0.blocks.3.attn.qkv.weight               -- torch.Size([1536, 512])\n",
      "backbone.encoder_layers.0.blocks.3.attn.qkv.bias                 -- torch.Size([1536])\n",
      "backbone.encoder_layers.0.blocks.3.attn.proj.weight              -- torch.Size([512, 512])\n",
      "backbone.encoder_layers.0.blocks.3.attn.proj.bias                -- torch.Size([512])\n",
      "backbone.encoder_layers.0.blocks.3.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 512])\n",
      "backbone.encoder_layers.0.blocks.3.attn.lora_proj.loras.0.lora_B -- torch.Size([512, 8])\n",
      "backbone.encoder_layers.0.blocks.3.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 512])\n",
      "backbone.encoder_layers.0.blocks.3.attn.lora_qkv.loras.0.lora_B  -- torch.Size([1536, 8])\n",
      "backbone.encoder_layers.0.blocks.3.norm2.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.encoder_layers.0.blocks.3.norm2.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.encoder_layers.0.blocks.3.mlp.fc1.weight                -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.0.blocks.3.mlp.fc1.bias                  -- torch.Size([2048])\n",
      "backbone.encoder_layers.0.blocks.3.mlp.fc2.weight                -- torch.Size([512, 2048])\n",
      "backbone.encoder_layers.0.blocks.3.mlp.fc2.bias                  -- torch.Size([512])\n",
      "backbone.encoder_layers.0.blocks.4.norm1.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.encoder_layers.0.blocks.4.norm1.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.encoder_layers.0.blocks.4.attn.qkv.weight               -- torch.Size([1536, 512])\n",
      "backbone.encoder_layers.0.blocks.4.attn.qkv.bias                 -- torch.Size([1536])\n",
      "backbone.encoder_layers.0.blocks.4.attn.proj.weight              -- torch.Size([512, 512])\n",
      "backbone.encoder_layers.0.blocks.4.attn.proj.bias                -- torch.Size([512])\n",
      "backbone.encoder_layers.0.blocks.4.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 512])\n",
      "backbone.encoder_layers.0.blocks.4.attn.lora_proj.loras.0.lora_B -- torch.Size([512, 8])\n",
      "backbone.encoder_layers.0.blocks.4.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 512])\n",
      "backbone.encoder_layers.0.blocks.4.attn.lora_qkv.loras.0.lora_B  -- torch.Size([1536, 8])\n",
      "backbone.encoder_layers.0.blocks.4.norm2.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.encoder_layers.0.blocks.4.norm2.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.encoder_layers.0.blocks.4.mlp.fc1.weight                -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.0.blocks.4.mlp.fc1.bias                  -- torch.Size([2048])\n",
      "backbone.encoder_layers.0.blocks.4.mlp.fc2.weight                -- torch.Size([512, 2048])\n",
      "backbone.encoder_layers.0.blocks.4.mlp.fc2.bias                  -- torch.Size([512])\n",
      "backbone.encoder_layers.0.blocks.5.norm1.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.encoder_layers.0.blocks.5.norm1.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.encoder_layers.0.blocks.5.attn.qkv.weight               -- torch.Size([1536, 512])\n",
      "backbone.encoder_layers.0.blocks.5.attn.qkv.bias                 -- torch.Size([1536])\n",
      "backbone.encoder_layers.0.blocks.5.attn.proj.weight              -- torch.Size([512, 512])\n",
      "backbone.encoder_layers.0.blocks.5.attn.proj.bias                -- torch.Size([512])\n",
      "backbone.encoder_layers.0.blocks.5.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 512])\n",
      "backbone.encoder_layers.0.blocks.5.attn.lora_proj.loras.0.lora_B -- torch.Size([512, 8])\n",
      "backbone.encoder_layers.0.blocks.5.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 512])\n",
      "backbone.encoder_layers.0.blocks.5.attn.lora_qkv.loras.0.lora_B  -- torch.Size([1536, 8])\n",
      "backbone.encoder_layers.0.blocks.5.norm2.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.encoder_layers.0.blocks.5.norm2.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.encoder_layers.0.blocks.5.mlp.fc1.weight                -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.0.blocks.5.mlp.fc1.bias                  -- torch.Size([2048])\n",
      "backbone.encoder_layers.0.blocks.5.mlp.fc2.weight                -- torch.Size([512, 2048])\n",
      "backbone.encoder_layers.0.blocks.5.mlp.fc2.bias                  -- torch.Size([512])\n",
      "backbone.encoder_layers.0.downsample.reduction.weight            -- torch.Size([1024, 2048])\n",
      "backbone.encoder_layers.0.downsample.norm.weight                 -- torch.Size([2048])\n",
      "backbone.encoder_layers.0.downsample.norm.bias                   -- torch.Size([2048])\n",
      "backbone.encoder_layers.1.blocks.0.norm1.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.1.blocks.0.norm1.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.encoder_layers.1.blocks.0.attn.qkv.weight               -- torch.Size([3072, 1024])\n",
      "backbone.encoder_layers.1.blocks.0.attn.qkv.bias                 -- torch.Size([3072])\n",
      "backbone.encoder_layers.1.blocks.0.attn.proj.weight              -- torch.Size([1024, 1024])\n",
      "backbone.encoder_layers.1.blocks.0.attn.proj.bias                -- torch.Size([1024])\n",
      "backbone.encoder_layers.1.blocks.0.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 1024])\n",
      "backbone.encoder_layers.1.blocks.0.attn.lora_proj.loras.0.lora_B -- torch.Size([1024, 8])\n",
      "backbone.encoder_layers.1.blocks.0.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 1024])\n",
      "backbone.encoder_layers.1.blocks.0.attn.lora_qkv.loras.0.lora_B  -- torch.Size([3072, 8])\n",
      "backbone.encoder_layers.1.blocks.0.norm2.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.1.blocks.0.norm2.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.encoder_layers.1.blocks.0.mlp.fc1.weight                -- torch.Size([4096, 1024])\n",
      "backbone.encoder_layers.1.blocks.0.mlp.fc1.bias                  -- torch.Size([4096])\n",
      "backbone.encoder_layers.1.blocks.0.mlp.fc2.weight                -- torch.Size([1024, 4096])\n",
      "backbone.encoder_layers.1.blocks.0.mlp.fc2.bias                  -- torch.Size([1024])\n",
      "backbone.encoder_layers.1.blocks.1.norm1.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.1.blocks.1.norm1.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.encoder_layers.1.blocks.1.attn.qkv.weight               -- torch.Size([3072, 1024])\n",
      "backbone.encoder_layers.1.blocks.1.attn.qkv.bias                 -- torch.Size([3072])\n",
      "backbone.encoder_layers.1.blocks.1.attn.proj.weight              -- torch.Size([1024, 1024])\n",
      "backbone.encoder_layers.1.blocks.1.attn.proj.bias                -- torch.Size([1024])\n",
      "backbone.encoder_layers.1.blocks.1.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 1024])\n",
      "backbone.encoder_layers.1.blocks.1.attn.lora_proj.loras.0.lora_B -- torch.Size([1024, 8])\n",
      "backbone.encoder_layers.1.blocks.1.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 1024])\n",
      "backbone.encoder_layers.1.blocks.1.attn.lora_qkv.loras.0.lora_B  -- torch.Size([3072, 8])\n",
      "backbone.encoder_layers.1.blocks.1.norm2.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.1.blocks.1.norm2.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.encoder_layers.1.blocks.1.mlp.fc1.weight                -- torch.Size([4096, 1024])\n",
      "backbone.encoder_layers.1.blocks.1.mlp.fc1.bias                  -- torch.Size([4096])\n",
      "backbone.encoder_layers.1.blocks.1.mlp.fc2.weight                -- torch.Size([1024, 4096])\n",
      "backbone.encoder_layers.1.blocks.1.mlp.fc2.bias                  -- torch.Size([1024])\n",
      "backbone.encoder_layers.1.blocks.2.norm1.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.1.blocks.2.norm1.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.encoder_layers.1.blocks.2.attn.qkv.weight               -- torch.Size([3072, 1024])\n",
      "backbone.encoder_layers.1.blocks.2.attn.qkv.bias                 -- torch.Size([3072])\n",
      "backbone.encoder_layers.1.blocks.2.attn.proj.weight              -- torch.Size([1024, 1024])\n",
      "backbone.encoder_layers.1.blocks.2.attn.proj.bias                -- torch.Size([1024])\n",
      "backbone.encoder_layers.1.blocks.2.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 1024])\n",
      "backbone.encoder_layers.1.blocks.2.attn.lora_proj.loras.0.lora_B -- torch.Size([1024, 8])\n",
      "backbone.encoder_layers.1.blocks.2.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 1024])\n",
      "backbone.encoder_layers.1.blocks.2.attn.lora_qkv.loras.0.lora_B  -- torch.Size([3072, 8])\n",
      "backbone.encoder_layers.1.blocks.2.norm2.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.1.blocks.2.norm2.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.encoder_layers.1.blocks.2.mlp.fc1.weight                -- torch.Size([4096, 1024])\n",
      "backbone.encoder_layers.1.blocks.2.mlp.fc1.bias                  -- torch.Size([4096])\n",
      "backbone.encoder_layers.1.blocks.2.mlp.fc2.weight                -- torch.Size([1024, 4096])\n",
      "backbone.encoder_layers.1.blocks.2.mlp.fc2.bias                  -- torch.Size([1024])\n",
      "backbone.encoder_layers.1.blocks.3.norm1.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.1.blocks.3.norm1.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.encoder_layers.1.blocks.3.attn.qkv.weight               -- torch.Size([3072, 1024])\n",
      "backbone.encoder_layers.1.blocks.3.attn.qkv.bias                 -- torch.Size([3072])\n",
      "backbone.encoder_layers.1.blocks.3.attn.proj.weight              -- torch.Size([1024, 1024])\n",
      "backbone.encoder_layers.1.blocks.3.attn.proj.bias                -- torch.Size([1024])\n",
      "backbone.encoder_layers.1.blocks.3.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 1024])\n",
      "backbone.encoder_layers.1.blocks.3.attn.lora_proj.loras.0.lora_B -- torch.Size([1024, 8])\n",
      "backbone.encoder_layers.1.blocks.3.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 1024])\n",
      "backbone.encoder_layers.1.blocks.3.attn.lora_qkv.loras.0.lora_B  -- torch.Size([3072, 8])\n",
      "backbone.encoder_layers.1.blocks.3.norm2.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.1.blocks.3.norm2.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.encoder_layers.1.blocks.3.mlp.fc1.weight                -- torch.Size([4096, 1024])\n",
      "backbone.encoder_layers.1.blocks.3.mlp.fc1.bias                  -- torch.Size([4096])\n",
      "backbone.encoder_layers.1.blocks.3.mlp.fc2.weight                -- torch.Size([1024, 4096])\n",
      "backbone.encoder_layers.1.blocks.3.mlp.fc2.bias                  -- torch.Size([1024])\n",
      "backbone.encoder_layers.1.blocks.4.norm1.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.1.blocks.4.norm1.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.encoder_layers.1.blocks.4.attn.qkv.weight               -- torch.Size([3072, 1024])\n",
      "backbone.encoder_layers.1.blocks.4.attn.qkv.bias                 -- torch.Size([3072])\n",
      "backbone.encoder_layers.1.blocks.4.attn.proj.weight              -- torch.Size([1024, 1024])\n",
      "backbone.encoder_layers.1.blocks.4.attn.proj.bias                -- torch.Size([1024])\n",
      "backbone.encoder_layers.1.blocks.4.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 1024])\n",
      "backbone.encoder_layers.1.blocks.4.attn.lora_proj.loras.0.lora_B -- torch.Size([1024, 8])\n",
      "backbone.encoder_layers.1.blocks.4.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 1024])\n",
      "backbone.encoder_layers.1.blocks.4.attn.lora_qkv.loras.0.lora_B  -- torch.Size([3072, 8])\n",
      "backbone.encoder_layers.1.blocks.4.norm2.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.1.blocks.4.norm2.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.encoder_layers.1.blocks.4.mlp.fc1.weight                -- torch.Size([4096, 1024])\n",
      "backbone.encoder_layers.1.blocks.4.mlp.fc1.bias                  -- torch.Size([4096])\n",
      "backbone.encoder_layers.1.blocks.4.mlp.fc2.weight                -- torch.Size([1024, 4096])\n",
      "backbone.encoder_layers.1.blocks.4.mlp.fc2.bias                  -- torch.Size([1024])\n",
      "backbone.encoder_layers.1.blocks.5.norm1.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.1.blocks.5.norm1.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.encoder_layers.1.blocks.5.attn.qkv.weight               -- torch.Size([3072, 1024])\n",
      "backbone.encoder_layers.1.blocks.5.attn.qkv.bias                 -- torch.Size([3072])\n",
      "backbone.encoder_layers.1.blocks.5.attn.proj.weight              -- torch.Size([1024, 1024])\n",
      "backbone.encoder_layers.1.blocks.5.attn.proj.bias                -- torch.Size([1024])\n",
      "backbone.encoder_layers.1.blocks.5.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 1024])\n",
      "backbone.encoder_layers.1.blocks.5.attn.lora_proj.loras.0.lora_B -- torch.Size([1024, 8])\n",
      "backbone.encoder_layers.1.blocks.5.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 1024])\n",
      "backbone.encoder_layers.1.blocks.5.attn.lora_qkv.loras.0.lora_B  -- torch.Size([3072, 8])\n",
      "backbone.encoder_layers.1.blocks.5.norm2.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.1.blocks.5.norm2.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.encoder_layers.1.blocks.5.mlp.fc1.weight                -- torch.Size([4096, 1024])\n",
      "backbone.encoder_layers.1.blocks.5.mlp.fc1.bias                  -- torch.Size([4096])\n",
      "backbone.encoder_layers.1.blocks.5.mlp.fc2.weight                -- torch.Size([1024, 4096])\n",
      "backbone.encoder_layers.1.blocks.5.mlp.fc2.bias                  -- torch.Size([1024])\n",
      "backbone.encoder_layers.1.blocks.6.norm1.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.1.blocks.6.norm1.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.encoder_layers.1.blocks.6.attn.qkv.weight               -- torch.Size([3072, 1024])\n",
      "backbone.encoder_layers.1.blocks.6.attn.qkv.bias                 -- torch.Size([3072])\n",
      "backbone.encoder_layers.1.blocks.6.attn.proj.weight              -- torch.Size([1024, 1024])\n",
      "backbone.encoder_layers.1.blocks.6.attn.proj.bias                -- torch.Size([1024])\n",
      "backbone.encoder_layers.1.blocks.6.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 1024])\n",
      "backbone.encoder_layers.1.blocks.6.attn.lora_proj.loras.0.lora_B -- torch.Size([1024, 8])\n",
      "backbone.encoder_layers.1.blocks.6.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 1024])\n",
      "backbone.encoder_layers.1.blocks.6.attn.lora_qkv.loras.0.lora_B  -- torch.Size([3072, 8])\n",
      "backbone.encoder_layers.1.blocks.6.norm2.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.1.blocks.6.norm2.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.encoder_layers.1.blocks.6.mlp.fc1.weight                -- torch.Size([4096, 1024])\n",
      "backbone.encoder_layers.1.blocks.6.mlp.fc1.bias                  -- torch.Size([4096])\n",
      "backbone.encoder_layers.1.blocks.6.mlp.fc2.weight                -- torch.Size([1024, 4096])\n",
      "backbone.encoder_layers.1.blocks.6.mlp.fc2.bias                  -- torch.Size([1024])\n",
      "backbone.encoder_layers.1.blocks.7.norm1.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.1.blocks.7.norm1.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.encoder_layers.1.blocks.7.attn.qkv.weight               -- torch.Size([3072, 1024])\n",
      "backbone.encoder_layers.1.blocks.7.attn.qkv.bias                 -- torch.Size([3072])\n",
      "backbone.encoder_layers.1.blocks.7.attn.proj.weight              -- torch.Size([1024, 1024])\n",
      "backbone.encoder_layers.1.blocks.7.attn.proj.bias                -- torch.Size([1024])\n",
      "backbone.encoder_layers.1.blocks.7.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 1024])\n",
      "backbone.encoder_layers.1.blocks.7.attn.lora_proj.loras.0.lora_B -- torch.Size([1024, 8])\n",
      "backbone.encoder_layers.1.blocks.7.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 1024])\n",
      "backbone.encoder_layers.1.blocks.7.attn.lora_qkv.loras.0.lora_B  -- torch.Size([3072, 8])\n",
      "backbone.encoder_layers.1.blocks.7.norm2.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.1.blocks.7.norm2.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.encoder_layers.1.blocks.7.mlp.fc1.weight                -- torch.Size([4096, 1024])\n",
      "backbone.encoder_layers.1.blocks.7.mlp.fc1.bias                  -- torch.Size([4096])\n",
      "backbone.encoder_layers.1.blocks.7.mlp.fc2.weight                -- torch.Size([1024, 4096])\n",
      "backbone.encoder_layers.1.blocks.7.mlp.fc2.bias                  -- torch.Size([1024])\n",
      "backbone.encoder_layers.1.blocks.8.norm1.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.1.blocks.8.norm1.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.encoder_layers.1.blocks.8.attn.qkv.weight               -- torch.Size([3072, 1024])\n",
      "backbone.encoder_layers.1.blocks.8.attn.qkv.bias                 -- torch.Size([3072])\n",
      "backbone.encoder_layers.1.blocks.8.attn.proj.weight              -- torch.Size([1024, 1024])\n",
      "backbone.encoder_layers.1.blocks.8.attn.proj.bias                -- torch.Size([1024])\n",
      "backbone.encoder_layers.1.blocks.8.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 1024])\n",
      "backbone.encoder_layers.1.blocks.8.attn.lora_proj.loras.0.lora_B -- torch.Size([1024, 8])\n",
      "backbone.encoder_layers.1.blocks.8.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 1024])\n",
      "backbone.encoder_layers.1.blocks.8.attn.lora_qkv.loras.0.lora_B  -- torch.Size([3072, 8])\n",
      "backbone.encoder_layers.1.blocks.8.norm2.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.1.blocks.8.norm2.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.encoder_layers.1.blocks.8.mlp.fc1.weight                -- torch.Size([4096, 1024])\n",
      "backbone.encoder_layers.1.blocks.8.mlp.fc1.bias                  -- torch.Size([4096])\n",
      "backbone.encoder_layers.1.blocks.8.mlp.fc2.weight                -- torch.Size([1024, 4096])\n",
      "backbone.encoder_layers.1.blocks.8.mlp.fc2.bias                  -- torch.Size([1024])\n",
      "backbone.encoder_layers.1.blocks.9.norm1.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.1.blocks.9.norm1.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.encoder_layers.1.blocks.9.attn.qkv.weight               -- torch.Size([3072, 1024])\n",
      "backbone.encoder_layers.1.blocks.9.attn.qkv.bias                 -- torch.Size([3072])\n",
      "backbone.encoder_layers.1.blocks.9.attn.proj.weight              -- torch.Size([1024, 1024])\n",
      "backbone.encoder_layers.1.blocks.9.attn.proj.bias                -- torch.Size([1024])\n",
      "backbone.encoder_layers.1.blocks.9.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 1024])\n",
      "backbone.encoder_layers.1.blocks.9.attn.lora_proj.loras.0.lora_B -- torch.Size([1024, 8])\n",
      "backbone.encoder_layers.1.blocks.9.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 1024])\n",
      "backbone.encoder_layers.1.blocks.9.attn.lora_qkv.loras.0.lora_B  -- torch.Size([3072, 8])\n",
      "backbone.encoder_layers.1.blocks.9.norm2.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.encoder_layers.1.blocks.9.norm2.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.encoder_layers.1.blocks.9.mlp.fc1.weight                -- torch.Size([4096, 1024])\n",
      "backbone.encoder_layers.1.blocks.9.mlp.fc1.bias                  -- torch.Size([4096])\n",
      "backbone.encoder_layers.1.blocks.9.mlp.fc2.weight                -- torch.Size([1024, 4096])\n",
      "backbone.encoder_layers.1.blocks.9.mlp.fc2.bias                  -- torch.Size([1024])\n",
      "backbone.encoder_layers.1.downsample.reduction.weight            -- torch.Size([2048, 4096])\n",
      "backbone.encoder_layers.1.downsample.norm.weight                 -- torch.Size([4096])\n",
      "backbone.encoder_layers.1.downsample.norm.bias                   -- torch.Size([4096])\n",
      "backbone.encoder_layers.2.blocks.0.norm1.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.encoder_layers.2.blocks.0.norm1.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.encoder_layers.2.blocks.0.attn.qkv.weight               -- torch.Size([6144, 2048])\n",
      "backbone.encoder_layers.2.blocks.0.attn.qkv.bias                 -- torch.Size([6144])\n",
      "backbone.encoder_layers.2.blocks.0.attn.proj.weight              -- torch.Size([2048, 2048])\n",
      "backbone.encoder_layers.2.blocks.0.attn.proj.bias                -- torch.Size([2048])\n",
      "backbone.encoder_layers.2.blocks.0.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 2048])\n",
      "backbone.encoder_layers.2.blocks.0.attn.lora_proj.loras.0.lora_B -- torch.Size([2048, 8])\n",
      "backbone.encoder_layers.2.blocks.0.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 2048])\n",
      "backbone.encoder_layers.2.blocks.0.attn.lora_qkv.loras.0.lora_B  -- torch.Size([6144, 8])\n",
      "backbone.encoder_layers.2.blocks.0.norm2.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.encoder_layers.2.blocks.0.norm2.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.encoder_layers.2.blocks.0.mlp.fc1.weight                -- torch.Size([8192, 2048])\n",
      "backbone.encoder_layers.2.blocks.0.mlp.fc1.bias                  -- torch.Size([8192])\n",
      "backbone.encoder_layers.2.blocks.0.mlp.fc2.weight                -- torch.Size([2048, 8192])\n",
      "backbone.encoder_layers.2.blocks.0.mlp.fc2.bias                  -- torch.Size([2048])\n",
      "backbone.encoder_layers.2.blocks.1.norm1.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.encoder_layers.2.blocks.1.norm1.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.encoder_layers.2.blocks.1.attn.qkv.weight               -- torch.Size([6144, 2048])\n",
      "backbone.encoder_layers.2.blocks.1.attn.qkv.bias                 -- torch.Size([6144])\n",
      "backbone.encoder_layers.2.blocks.1.attn.proj.weight              -- torch.Size([2048, 2048])\n",
      "backbone.encoder_layers.2.blocks.1.attn.proj.bias                -- torch.Size([2048])\n",
      "backbone.encoder_layers.2.blocks.1.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 2048])\n",
      "backbone.encoder_layers.2.blocks.1.attn.lora_proj.loras.0.lora_B -- torch.Size([2048, 8])\n",
      "backbone.encoder_layers.2.blocks.1.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 2048])\n",
      "backbone.encoder_layers.2.blocks.1.attn.lora_qkv.loras.0.lora_B  -- torch.Size([6144, 8])\n",
      "backbone.encoder_layers.2.blocks.1.norm2.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.encoder_layers.2.blocks.1.norm2.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.encoder_layers.2.blocks.1.mlp.fc1.weight                -- torch.Size([8192, 2048])\n",
      "backbone.encoder_layers.2.blocks.1.mlp.fc1.bias                  -- torch.Size([8192])\n",
      "backbone.encoder_layers.2.blocks.1.mlp.fc2.weight                -- torch.Size([2048, 8192])\n",
      "backbone.encoder_layers.2.blocks.1.mlp.fc2.bias                  -- torch.Size([2048])\n",
      "backbone.encoder_layers.2.blocks.2.norm1.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.encoder_layers.2.blocks.2.norm1.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.encoder_layers.2.blocks.2.attn.qkv.weight               -- torch.Size([6144, 2048])\n",
      "backbone.encoder_layers.2.blocks.2.attn.qkv.bias                 -- torch.Size([6144])\n",
      "backbone.encoder_layers.2.blocks.2.attn.proj.weight              -- torch.Size([2048, 2048])\n",
      "backbone.encoder_layers.2.blocks.2.attn.proj.bias                -- torch.Size([2048])\n",
      "backbone.encoder_layers.2.blocks.2.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 2048])\n",
      "backbone.encoder_layers.2.blocks.2.attn.lora_proj.loras.0.lora_B -- torch.Size([2048, 8])\n",
      "backbone.encoder_layers.2.blocks.2.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 2048])\n",
      "backbone.encoder_layers.2.blocks.2.attn.lora_qkv.loras.0.lora_B  -- torch.Size([6144, 8])\n",
      "backbone.encoder_layers.2.blocks.2.norm2.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.encoder_layers.2.blocks.2.norm2.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.encoder_layers.2.blocks.2.mlp.fc1.weight                -- torch.Size([8192, 2048])\n",
      "backbone.encoder_layers.2.blocks.2.mlp.fc1.bias                  -- torch.Size([8192])\n",
      "backbone.encoder_layers.2.blocks.2.mlp.fc2.weight                -- torch.Size([2048, 8192])\n",
      "backbone.encoder_layers.2.blocks.2.mlp.fc2.bias                  -- torch.Size([2048])\n",
      "backbone.encoder_layers.2.blocks.3.norm1.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.encoder_layers.2.blocks.3.norm1.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.encoder_layers.2.blocks.3.attn.qkv.weight               -- torch.Size([6144, 2048])\n",
      "backbone.encoder_layers.2.blocks.3.attn.qkv.bias                 -- torch.Size([6144])\n",
      "backbone.encoder_layers.2.blocks.3.attn.proj.weight              -- torch.Size([2048, 2048])\n",
      "backbone.encoder_layers.2.blocks.3.attn.proj.bias                -- torch.Size([2048])\n",
      "backbone.encoder_layers.2.blocks.3.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 2048])\n",
      "backbone.encoder_layers.2.blocks.3.attn.lora_proj.loras.0.lora_B -- torch.Size([2048, 8])\n",
      "backbone.encoder_layers.2.blocks.3.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 2048])\n",
      "backbone.encoder_layers.2.blocks.3.attn.lora_qkv.loras.0.lora_B  -- torch.Size([6144, 8])\n",
      "backbone.encoder_layers.2.blocks.3.norm2.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.encoder_layers.2.blocks.3.norm2.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.encoder_layers.2.blocks.3.mlp.fc1.weight                -- torch.Size([8192, 2048])\n",
      "backbone.encoder_layers.2.blocks.3.mlp.fc1.bias                  -- torch.Size([8192])\n",
      "backbone.encoder_layers.2.blocks.3.mlp.fc2.weight                -- torch.Size([2048, 8192])\n",
      "backbone.encoder_layers.2.blocks.3.mlp.fc2.bias                  -- torch.Size([2048])\n",
      "backbone.encoder_layers.2.blocks.4.norm1.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.encoder_layers.2.blocks.4.norm1.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.encoder_layers.2.blocks.4.attn.qkv.weight               -- torch.Size([6144, 2048])\n",
      "backbone.encoder_layers.2.blocks.4.attn.qkv.bias                 -- torch.Size([6144])\n",
      "backbone.encoder_layers.2.blocks.4.attn.proj.weight              -- torch.Size([2048, 2048])\n",
      "backbone.encoder_layers.2.blocks.4.attn.proj.bias                -- torch.Size([2048])\n",
      "backbone.encoder_layers.2.blocks.4.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 2048])\n",
      "backbone.encoder_layers.2.blocks.4.attn.lora_proj.loras.0.lora_B -- torch.Size([2048, 8])\n",
      "backbone.encoder_layers.2.blocks.4.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 2048])\n",
      "backbone.encoder_layers.2.blocks.4.attn.lora_qkv.loras.0.lora_B  -- torch.Size([6144, 8])\n",
      "backbone.encoder_layers.2.blocks.4.norm2.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.encoder_layers.2.blocks.4.norm2.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.encoder_layers.2.blocks.4.mlp.fc1.weight                -- torch.Size([8192, 2048])\n",
      "backbone.encoder_layers.2.blocks.4.mlp.fc1.bias                  -- torch.Size([8192])\n",
      "backbone.encoder_layers.2.blocks.4.mlp.fc2.weight                -- torch.Size([2048, 8192])\n",
      "backbone.encoder_layers.2.blocks.4.mlp.fc2.bias                  -- torch.Size([2048])\n",
      "backbone.encoder_layers.2.blocks.5.norm1.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.encoder_layers.2.blocks.5.norm1.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.encoder_layers.2.blocks.5.attn.qkv.weight               -- torch.Size([6144, 2048])\n",
      "backbone.encoder_layers.2.blocks.5.attn.qkv.bias                 -- torch.Size([6144])\n",
      "backbone.encoder_layers.2.blocks.5.attn.proj.weight              -- torch.Size([2048, 2048])\n",
      "backbone.encoder_layers.2.blocks.5.attn.proj.bias                -- torch.Size([2048])\n",
      "backbone.encoder_layers.2.blocks.5.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 2048])\n",
      "backbone.encoder_layers.2.blocks.5.attn.lora_proj.loras.0.lora_B -- torch.Size([2048, 8])\n",
      "backbone.encoder_layers.2.blocks.5.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 2048])\n",
      "backbone.encoder_layers.2.blocks.5.attn.lora_qkv.loras.0.lora_B  -- torch.Size([6144, 8])\n",
      "backbone.encoder_layers.2.blocks.5.norm2.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.encoder_layers.2.blocks.5.norm2.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.encoder_layers.2.blocks.5.mlp.fc1.weight                -- torch.Size([8192, 2048])\n",
      "backbone.encoder_layers.2.blocks.5.mlp.fc1.bias                  -- torch.Size([8192])\n",
      "backbone.encoder_layers.2.blocks.5.mlp.fc2.weight                -- torch.Size([2048, 8192])\n",
      "backbone.encoder_layers.2.blocks.5.mlp.fc2.bias                  -- torch.Size([2048])\n",
      "backbone.encoder_layers.2.blocks.6.norm1.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.encoder_layers.2.blocks.6.norm1.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.encoder_layers.2.blocks.6.attn.qkv.weight               -- torch.Size([6144, 2048])\n",
      "backbone.encoder_layers.2.blocks.6.attn.qkv.bias                 -- torch.Size([6144])\n",
      "backbone.encoder_layers.2.blocks.6.attn.proj.weight              -- torch.Size([2048, 2048])\n",
      "backbone.encoder_layers.2.blocks.6.attn.proj.bias                -- torch.Size([2048])\n",
      "backbone.encoder_layers.2.blocks.6.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 2048])\n",
      "backbone.encoder_layers.2.blocks.6.attn.lora_proj.loras.0.lora_B -- torch.Size([2048, 8])\n",
      "backbone.encoder_layers.2.blocks.6.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 2048])\n",
      "backbone.encoder_layers.2.blocks.6.attn.lora_qkv.loras.0.lora_B  -- torch.Size([6144, 8])\n",
      "backbone.encoder_layers.2.blocks.6.norm2.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.encoder_layers.2.blocks.6.norm2.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.encoder_layers.2.blocks.6.mlp.fc1.weight                -- torch.Size([8192, 2048])\n",
      "backbone.encoder_layers.2.blocks.6.mlp.fc1.bias                  -- torch.Size([8192])\n",
      "backbone.encoder_layers.2.blocks.6.mlp.fc2.weight                -- torch.Size([2048, 8192])\n",
      "backbone.encoder_layers.2.blocks.6.mlp.fc2.bias                  -- torch.Size([2048])\n",
      "backbone.encoder_layers.2.blocks.7.norm1.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.encoder_layers.2.blocks.7.norm1.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.encoder_layers.2.blocks.7.attn.qkv.weight               -- torch.Size([6144, 2048])\n",
      "backbone.encoder_layers.2.blocks.7.attn.qkv.bias                 -- torch.Size([6144])\n",
      "backbone.encoder_layers.2.blocks.7.attn.proj.weight              -- torch.Size([2048, 2048])\n",
      "backbone.encoder_layers.2.blocks.7.attn.proj.bias                -- torch.Size([2048])\n",
      "backbone.encoder_layers.2.blocks.7.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 2048])\n",
      "backbone.encoder_layers.2.blocks.7.attn.lora_proj.loras.0.lora_B -- torch.Size([2048, 8])\n",
      "backbone.encoder_layers.2.blocks.7.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 2048])\n",
      "backbone.encoder_layers.2.blocks.7.attn.lora_qkv.loras.0.lora_B  -- torch.Size([6144, 8])\n",
      "backbone.encoder_layers.2.blocks.7.norm2.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.encoder_layers.2.blocks.7.norm2.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.encoder_layers.2.blocks.7.mlp.fc1.weight                -- torch.Size([8192, 2048])\n",
      "backbone.encoder_layers.2.blocks.7.mlp.fc1.bias                  -- torch.Size([8192])\n",
      "backbone.encoder_layers.2.blocks.7.mlp.fc2.weight                -- torch.Size([2048, 8192])\n",
      "backbone.encoder_layers.2.blocks.7.mlp.fc2.bias                  -- torch.Size([2048])\n",
      "backbone.decoder_layers.0.blocks.0.norm1.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.decoder_layers.0.blocks.0.norm1.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.decoder_layers.0.blocks.0.attn.qkv.weight               -- torch.Size([6144, 2048])\n",
      "backbone.decoder_layers.0.blocks.0.attn.qkv.bias                 -- torch.Size([6144])\n",
      "backbone.decoder_layers.0.blocks.0.attn.proj.weight              -- torch.Size([2048, 2048])\n",
      "backbone.decoder_layers.0.blocks.0.attn.proj.bias                -- torch.Size([2048])\n",
      "backbone.decoder_layers.0.blocks.0.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 2048])\n",
      "backbone.decoder_layers.0.blocks.0.attn.lora_proj.loras.0.lora_B -- torch.Size([2048, 8])\n",
      "backbone.decoder_layers.0.blocks.0.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 2048])\n",
      "backbone.decoder_layers.0.blocks.0.attn.lora_qkv.loras.0.lora_B  -- torch.Size([6144, 8])\n",
      "backbone.decoder_layers.0.blocks.0.norm2.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.decoder_layers.0.blocks.0.norm2.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.decoder_layers.0.blocks.0.mlp.fc1.weight                -- torch.Size([8192, 2048])\n",
      "backbone.decoder_layers.0.blocks.0.mlp.fc1.bias                  -- torch.Size([8192])\n",
      "backbone.decoder_layers.0.blocks.0.mlp.fc2.weight                -- torch.Size([2048, 8192])\n",
      "backbone.decoder_layers.0.blocks.0.mlp.fc2.bias                  -- torch.Size([2048])\n",
      "backbone.decoder_layers.0.blocks.1.norm1.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.decoder_layers.0.blocks.1.norm1.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.decoder_layers.0.blocks.1.attn.qkv.weight               -- torch.Size([6144, 2048])\n",
      "backbone.decoder_layers.0.blocks.1.attn.qkv.bias                 -- torch.Size([6144])\n",
      "backbone.decoder_layers.0.blocks.1.attn.proj.weight              -- torch.Size([2048, 2048])\n",
      "backbone.decoder_layers.0.blocks.1.attn.proj.bias                -- torch.Size([2048])\n",
      "backbone.decoder_layers.0.blocks.1.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 2048])\n",
      "backbone.decoder_layers.0.blocks.1.attn.lora_proj.loras.0.lora_B -- torch.Size([2048, 8])\n",
      "backbone.decoder_layers.0.blocks.1.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 2048])\n",
      "backbone.decoder_layers.0.blocks.1.attn.lora_qkv.loras.0.lora_B  -- torch.Size([6144, 8])\n",
      "backbone.decoder_layers.0.blocks.1.norm2.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.decoder_layers.0.blocks.1.norm2.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.decoder_layers.0.blocks.1.mlp.fc1.weight                -- torch.Size([8192, 2048])\n",
      "backbone.decoder_layers.0.blocks.1.mlp.fc1.bias                  -- torch.Size([8192])\n",
      "backbone.decoder_layers.0.blocks.1.mlp.fc2.weight                -- torch.Size([2048, 8192])\n",
      "backbone.decoder_layers.0.blocks.1.mlp.fc2.bias                  -- torch.Size([2048])\n",
      "backbone.decoder_layers.0.blocks.2.norm1.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.decoder_layers.0.blocks.2.norm1.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.decoder_layers.0.blocks.2.attn.qkv.weight               -- torch.Size([6144, 2048])\n",
      "backbone.decoder_layers.0.blocks.2.attn.qkv.bias                 -- torch.Size([6144])\n",
      "backbone.decoder_layers.0.blocks.2.attn.proj.weight              -- torch.Size([2048, 2048])\n",
      "backbone.decoder_layers.0.blocks.2.attn.proj.bias                -- torch.Size([2048])\n",
      "backbone.decoder_layers.0.blocks.2.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 2048])\n",
      "backbone.decoder_layers.0.blocks.2.attn.lora_proj.loras.0.lora_B -- torch.Size([2048, 8])\n",
      "backbone.decoder_layers.0.blocks.2.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 2048])\n",
      "backbone.decoder_layers.0.blocks.2.attn.lora_qkv.loras.0.lora_B  -- torch.Size([6144, 8])\n",
      "backbone.decoder_layers.0.blocks.2.norm2.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.decoder_layers.0.blocks.2.norm2.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.decoder_layers.0.blocks.2.mlp.fc1.weight                -- torch.Size([8192, 2048])\n",
      "backbone.decoder_layers.0.blocks.2.mlp.fc1.bias                  -- torch.Size([8192])\n",
      "backbone.decoder_layers.0.blocks.2.mlp.fc2.weight                -- torch.Size([2048, 8192])\n",
      "backbone.decoder_layers.0.blocks.2.mlp.fc2.bias                  -- torch.Size([2048])\n",
      "backbone.decoder_layers.0.blocks.3.norm1.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.decoder_layers.0.blocks.3.norm1.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.decoder_layers.0.blocks.3.attn.qkv.weight               -- torch.Size([6144, 2048])\n",
      "backbone.decoder_layers.0.blocks.3.attn.qkv.bias                 -- torch.Size([6144])\n",
      "backbone.decoder_layers.0.blocks.3.attn.proj.weight              -- torch.Size([2048, 2048])\n",
      "backbone.decoder_layers.0.blocks.3.attn.proj.bias                -- torch.Size([2048])\n",
      "backbone.decoder_layers.0.blocks.3.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 2048])\n",
      "backbone.decoder_layers.0.blocks.3.attn.lora_proj.loras.0.lora_B -- torch.Size([2048, 8])\n",
      "backbone.decoder_layers.0.blocks.3.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 2048])\n",
      "backbone.decoder_layers.0.blocks.3.attn.lora_qkv.loras.0.lora_B  -- torch.Size([6144, 8])\n",
      "backbone.decoder_layers.0.blocks.3.norm2.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.decoder_layers.0.blocks.3.norm2.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.decoder_layers.0.blocks.3.mlp.fc1.weight                -- torch.Size([8192, 2048])\n",
      "backbone.decoder_layers.0.blocks.3.mlp.fc1.bias                  -- torch.Size([8192])\n",
      "backbone.decoder_layers.0.blocks.3.mlp.fc2.weight                -- torch.Size([2048, 8192])\n",
      "backbone.decoder_layers.0.blocks.3.mlp.fc2.bias                  -- torch.Size([2048])\n",
      "backbone.decoder_layers.0.blocks.4.norm1.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.decoder_layers.0.blocks.4.norm1.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.decoder_layers.0.blocks.4.attn.qkv.weight               -- torch.Size([6144, 2048])\n",
      "backbone.decoder_layers.0.blocks.4.attn.qkv.bias                 -- torch.Size([6144])\n",
      "backbone.decoder_layers.0.blocks.4.attn.proj.weight              -- torch.Size([2048, 2048])\n",
      "backbone.decoder_layers.0.blocks.4.attn.proj.bias                -- torch.Size([2048])\n",
      "backbone.decoder_layers.0.blocks.4.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 2048])\n",
      "backbone.decoder_layers.0.blocks.4.attn.lora_proj.loras.0.lora_B -- torch.Size([2048, 8])\n",
      "backbone.decoder_layers.0.blocks.4.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 2048])\n",
      "backbone.decoder_layers.0.blocks.4.attn.lora_qkv.loras.0.lora_B  -- torch.Size([6144, 8])\n",
      "backbone.decoder_layers.0.blocks.4.norm2.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.decoder_layers.0.blocks.4.norm2.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.decoder_layers.0.blocks.4.mlp.fc1.weight                -- torch.Size([8192, 2048])\n",
      "backbone.decoder_layers.0.blocks.4.mlp.fc1.bias                  -- torch.Size([8192])\n",
      "backbone.decoder_layers.0.blocks.4.mlp.fc2.weight                -- torch.Size([2048, 8192])\n",
      "backbone.decoder_layers.0.blocks.4.mlp.fc2.bias                  -- torch.Size([2048])\n",
      "backbone.decoder_layers.0.blocks.5.norm1.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.decoder_layers.0.blocks.5.norm1.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.decoder_layers.0.blocks.5.attn.qkv.weight               -- torch.Size([6144, 2048])\n",
      "backbone.decoder_layers.0.blocks.5.attn.qkv.bias                 -- torch.Size([6144])\n",
      "backbone.decoder_layers.0.blocks.5.attn.proj.weight              -- torch.Size([2048, 2048])\n",
      "backbone.decoder_layers.0.blocks.5.attn.proj.bias                -- torch.Size([2048])\n",
      "backbone.decoder_layers.0.blocks.5.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 2048])\n",
      "backbone.decoder_layers.0.blocks.5.attn.lora_proj.loras.0.lora_B -- torch.Size([2048, 8])\n",
      "backbone.decoder_layers.0.blocks.5.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 2048])\n",
      "backbone.decoder_layers.0.blocks.5.attn.lora_qkv.loras.0.lora_B  -- torch.Size([6144, 8])\n",
      "backbone.decoder_layers.0.blocks.5.norm2.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.decoder_layers.0.blocks.5.norm2.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.decoder_layers.0.blocks.5.mlp.fc1.weight                -- torch.Size([8192, 2048])\n",
      "backbone.decoder_layers.0.blocks.5.mlp.fc1.bias                  -- torch.Size([8192])\n",
      "backbone.decoder_layers.0.blocks.5.mlp.fc2.weight                -- torch.Size([2048, 8192])\n",
      "backbone.decoder_layers.0.blocks.5.mlp.fc2.bias                  -- torch.Size([2048])\n",
      "backbone.decoder_layers.0.blocks.6.norm1.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.decoder_layers.0.blocks.6.norm1.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.decoder_layers.0.blocks.6.attn.qkv.weight               -- torch.Size([6144, 2048])\n",
      "backbone.decoder_layers.0.blocks.6.attn.qkv.bias                 -- torch.Size([6144])\n",
      "backbone.decoder_layers.0.blocks.6.attn.proj.weight              -- torch.Size([2048, 2048])\n",
      "backbone.decoder_layers.0.blocks.6.attn.proj.bias                -- torch.Size([2048])\n",
      "backbone.decoder_layers.0.blocks.6.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 2048])\n",
      "backbone.decoder_layers.0.blocks.6.attn.lora_proj.loras.0.lora_B -- torch.Size([2048, 8])\n",
      "backbone.decoder_layers.0.blocks.6.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 2048])\n",
      "backbone.decoder_layers.0.blocks.6.attn.lora_qkv.loras.0.lora_B  -- torch.Size([6144, 8])\n",
      "backbone.decoder_layers.0.blocks.6.norm2.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.decoder_layers.0.blocks.6.norm2.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.decoder_layers.0.blocks.6.mlp.fc1.weight                -- torch.Size([8192, 2048])\n",
      "backbone.decoder_layers.0.blocks.6.mlp.fc1.bias                  -- torch.Size([8192])\n",
      "backbone.decoder_layers.0.blocks.6.mlp.fc2.weight                -- torch.Size([2048, 8192])\n",
      "backbone.decoder_layers.0.blocks.6.mlp.fc2.bias                  -- torch.Size([2048])\n",
      "backbone.decoder_layers.0.blocks.7.norm1.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.decoder_layers.0.blocks.7.norm1.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.decoder_layers.0.blocks.7.attn.qkv.weight               -- torch.Size([6144, 2048])\n",
      "backbone.decoder_layers.0.blocks.7.attn.qkv.bias                 -- torch.Size([6144])\n",
      "backbone.decoder_layers.0.blocks.7.attn.proj.weight              -- torch.Size([2048, 2048])\n",
      "backbone.decoder_layers.0.blocks.7.attn.proj.bias                -- torch.Size([2048])\n",
      "backbone.decoder_layers.0.blocks.7.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 2048])\n",
      "backbone.decoder_layers.0.blocks.7.attn.lora_proj.loras.0.lora_B -- torch.Size([2048, 8])\n",
      "backbone.decoder_layers.0.blocks.7.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 2048])\n",
      "backbone.decoder_layers.0.blocks.7.attn.lora_qkv.loras.0.lora_B  -- torch.Size([6144, 8])\n",
      "backbone.decoder_layers.0.blocks.7.norm2.ln_modulation.1.weight  -- torch.Size([4096, 512])\n",
      "backbone.decoder_layers.0.blocks.7.norm2.ln_modulation.1.bias    -- torch.Size([4096])\n",
      "backbone.decoder_layers.0.blocks.7.mlp.fc1.weight                -- torch.Size([8192, 2048])\n",
      "backbone.decoder_layers.0.blocks.7.mlp.fc1.bias                  -- torch.Size([8192])\n",
      "backbone.decoder_layers.0.blocks.7.mlp.fc2.weight                -- torch.Size([2048, 8192])\n",
      "backbone.decoder_layers.0.blocks.7.mlp.fc2.bias                  -- torch.Size([2048])\n",
      "backbone.decoder_layers.0.upsample.lin1.weight                   -- torch.Size([4096, 2048])\n",
      "backbone.decoder_layers.0.upsample.lin2.weight                   -- torch.Size([1024, 1024])\n",
      "backbone.decoder_layers.0.upsample.norm.weight                   -- torch.Size([1024])\n",
      "backbone.decoder_layers.0.upsample.norm.bias                     -- torch.Size([1024])\n",
      "backbone.decoder_layers.1.blocks.0.norm1.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.1.blocks.0.norm1.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.decoder_layers.1.blocks.0.attn.qkv.weight               -- torch.Size([3072, 1024])\n",
      "backbone.decoder_layers.1.blocks.0.attn.qkv.bias                 -- torch.Size([3072])\n",
      "backbone.decoder_layers.1.blocks.0.attn.proj.weight              -- torch.Size([1024, 1024])\n",
      "backbone.decoder_layers.1.blocks.0.attn.proj.bias                -- torch.Size([1024])\n",
      "backbone.decoder_layers.1.blocks.0.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 1024])\n",
      "backbone.decoder_layers.1.blocks.0.attn.lora_proj.loras.0.lora_B -- torch.Size([1024, 8])\n",
      "backbone.decoder_layers.1.blocks.0.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 1024])\n",
      "backbone.decoder_layers.1.blocks.0.attn.lora_qkv.loras.0.lora_B  -- torch.Size([3072, 8])\n",
      "backbone.decoder_layers.1.blocks.0.norm2.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.1.blocks.0.norm2.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.decoder_layers.1.blocks.0.mlp.fc1.weight                -- torch.Size([4096, 1024])\n",
      "backbone.decoder_layers.1.blocks.0.mlp.fc1.bias                  -- torch.Size([4096])\n",
      "backbone.decoder_layers.1.blocks.0.mlp.fc2.weight                -- torch.Size([1024, 4096])\n",
      "backbone.decoder_layers.1.blocks.0.mlp.fc2.bias                  -- torch.Size([1024])\n",
      "backbone.decoder_layers.1.blocks.1.norm1.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.1.blocks.1.norm1.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.decoder_layers.1.blocks.1.attn.qkv.weight               -- torch.Size([3072, 1024])\n",
      "backbone.decoder_layers.1.blocks.1.attn.qkv.bias                 -- torch.Size([3072])\n",
      "backbone.decoder_layers.1.blocks.1.attn.proj.weight              -- torch.Size([1024, 1024])\n",
      "backbone.decoder_layers.1.blocks.1.attn.proj.bias                -- torch.Size([1024])\n",
      "backbone.decoder_layers.1.blocks.1.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 1024])\n",
      "backbone.decoder_layers.1.blocks.1.attn.lora_proj.loras.0.lora_B -- torch.Size([1024, 8])\n",
      "backbone.decoder_layers.1.blocks.1.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 1024])\n",
      "backbone.decoder_layers.1.blocks.1.attn.lora_qkv.loras.0.lora_B  -- torch.Size([3072, 8])\n",
      "backbone.decoder_layers.1.blocks.1.norm2.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.1.blocks.1.norm2.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.decoder_layers.1.blocks.1.mlp.fc1.weight                -- torch.Size([4096, 1024])\n",
      "backbone.decoder_layers.1.blocks.1.mlp.fc1.bias                  -- torch.Size([4096])\n",
      "backbone.decoder_layers.1.blocks.1.mlp.fc2.weight                -- torch.Size([1024, 4096])\n",
      "backbone.decoder_layers.1.blocks.1.mlp.fc2.bias                  -- torch.Size([1024])\n",
      "backbone.decoder_layers.1.blocks.2.norm1.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.1.blocks.2.norm1.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.decoder_layers.1.blocks.2.attn.qkv.weight               -- torch.Size([3072, 1024])\n",
      "backbone.decoder_layers.1.blocks.2.attn.qkv.bias                 -- torch.Size([3072])\n",
      "backbone.decoder_layers.1.blocks.2.attn.proj.weight              -- torch.Size([1024, 1024])\n",
      "backbone.decoder_layers.1.blocks.2.attn.proj.bias                -- torch.Size([1024])\n",
      "backbone.decoder_layers.1.blocks.2.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 1024])\n",
      "backbone.decoder_layers.1.blocks.2.attn.lora_proj.loras.0.lora_B -- torch.Size([1024, 8])\n",
      "backbone.decoder_layers.1.blocks.2.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 1024])\n",
      "backbone.decoder_layers.1.blocks.2.attn.lora_qkv.loras.0.lora_B  -- torch.Size([3072, 8])\n",
      "backbone.decoder_layers.1.blocks.2.norm2.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.1.blocks.2.norm2.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.decoder_layers.1.blocks.2.mlp.fc1.weight                -- torch.Size([4096, 1024])\n",
      "backbone.decoder_layers.1.blocks.2.mlp.fc1.bias                  -- torch.Size([4096])\n",
      "backbone.decoder_layers.1.blocks.2.mlp.fc2.weight                -- torch.Size([1024, 4096])\n",
      "backbone.decoder_layers.1.blocks.2.mlp.fc2.bias                  -- torch.Size([1024])\n",
      "backbone.decoder_layers.1.blocks.3.norm1.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.1.blocks.3.norm1.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.decoder_layers.1.blocks.3.attn.qkv.weight               -- torch.Size([3072, 1024])\n",
      "backbone.decoder_layers.1.blocks.3.attn.qkv.bias                 -- torch.Size([3072])\n",
      "backbone.decoder_layers.1.blocks.3.attn.proj.weight              -- torch.Size([1024, 1024])\n",
      "backbone.decoder_layers.1.blocks.3.attn.proj.bias                -- torch.Size([1024])\n",
      "backbone.decoder_layers.1.blocks.3.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 1024])\n",
      "backbone.decoder_layers.1.blocks.3.attn.lora_proj.loras.0.lora_B -- torch.Size([1024, 8])\n",
      "backbone.decoder_layers.1.blocks.3.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 1024])\n",
      "backbone.decoder_layers.1.blocks.3.attn.lora_qkv.loras.0.lora_B  -- torch.Size([3072, 8])\n",
      "backbone.decoder_layers.1.blocks.3.norm2.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.1.blocks.3.norm2.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.decoder_layers.1.blocks.3.mlp.fc1.weight                -- torch.Size([4096, 1024])\n",
      "backbone.decoder_layers.1.blocks.3.mlp.fc1.bias                  -- torch.Size([4096])\n",
      "backbone.decoder_layers.1.blocks.3.mlp.fc2.weight                -- torch.Size([1024, 4096])\n",
      "backbone.decoder_layers.1.blocks.3.mlp.fc2.bias                  -- torch.Size([1024])\n",
      "backbone.decoder_layers.1.blocks.4.norm1.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.1.blocks.4.norm1.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.decoder_layers.1.blocks.4.attn.qkv.weight               -- torch.Size([3072, 1024])\n",
      "backbone.decoder_layers.1.blocks.4.attn.qkv.bias                 -- torch.Size([3072])\n",
      "backbone.decoder_layers.1.blocks.4.attn.proj.weight              -- torch.Size([1024, 1024])\n",
      "backbone.decoder_layers.1.blocks.4.attn.proj.bias                -- torch.Size([1024])\n",
      "backbone.decoder_layers.1.blocks.4.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 1024])\n",
      "backbone.decoder_layers.1.blocks.4.attn.lora_proj.loras.0.lora_B -- torch.Size([1024, 8])\n",
      "backbone.decoder_layers.1.blocks.4.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 1024])\n",
      "backbone.decoder_layers.1.blocks.4.attn.lora_qkv.loras.0.lora_B  -- torch.Size([3072, 8])\n",
      "backbone.decoder_layers.1.blocks.4.norm2.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.1.blocks.4.norm2.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.decoder_layers.1.blocks.4.mlp.fc1.weight                -- torch.Size([4096, 1024])\n",
      "backbone.decoder_layers.1.blocks.4.mlp.fc1.bias                  -- torch.Size([4096])\n",
      "backbone.decoder_layers.1.blocks.4.mlp.fc2.weight                -- torch.Size([1024, 4096])\n",
      "backbone.decoder_layers.1.blocks.4.mlp.fc2.bias                  -- torch.Size([1024])\n",
      "backbone.decoder_layers.1.blocks.5.norm1.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.1.blocks.5.norm1.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.decoder_layers.1.blocks.5.attn.qkv.weight               -- torch.Size([3072, 1024])\n",
      "backbone.decoder_layers.1.blocks.5.attn.qkv.bias                 -- torch.Size([3072])\n",
      "backbone.decoder_layers.1.blocks.5.attn.proj.weight              -- torch.Size([1024, 1024])\n",
      "backbone.decoder_layers.1.blocks.5.attn.proj.bias                -- torch.Size([1024])\n",
      "backbone.decoder_layers.1.blocks.5.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 1024])\n",
      "backbone.decoder_layers.1.blocks.5.attn.lora_proj.loras.0.lora_B -- torch.Size([1024, 8])\n",
      "backbone.decoder_layers.1.blocks.5.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 1024])\n",
      "backbone.decoder_layers.1.blocks.5.attn.lora_qkv.loras.0.lora_B  -- torch.Size([3072, 8])\n",
      "backbone.decoder_layers.1.blocks.5.norm2.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.1.blocks.5.norm2.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.decoder_layers.1.blocks.5.mlp.fc1.weight                -- torch.Size([4096, 1024])\n",
      "backbone.decoder_layers.1.blocks.5.mlp.fc1.bias                  -- torch.Size([4096])\n",
      "backbone.decoder_layers.1.blocks.5.mlp.fc2.weight                -- torch.Size([1024, 4096])\n",
      "backbone.decoder_layers.1.blocks.5.mlp.fc2.bias                  -- torch.Size([1024])\n",
      "backbone.decoder_layers.1.blocks.6.norm1.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.1.blocks.6.norm1.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.decoder_layers.1.blocks.6.attn.qkv.weight               -- torch.Size([3072, 1024])\n",
      "backbone.decoder_layers.1.blocks.6.attn.qkv.bias                 -- torch.Size([3072])\n",
      "backbone.decoder_layers.1.blocks.6.attn.proj.weight              -- torch.Size([1024, 1024])\n",
      "backbone.decoder_layers.1.blocks.6.attn.proj.bias                -- torch.Size([1024])\n",
      "backbone.decoder_layers.1.blocks.6.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 1024])\n",
      "backbone.decoder_layers.1.blocks.6.attn.lora_proj.loras.0.lora_B -- torch.Size([1024, 8])\n",
      "backbone.decoder_layers.1.blocks.6.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 1024])\n",
      "backbone.decoder_layers.1.blocks.6.attn.lora_qkv.loras.0.lora_B  -- torch.Size([3072, 8])\n",
      "backbone.decoder_layers.1.blocks.6.norm2.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.1.blocks.6.norm2.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.decoder_layers.1.blocks.6.mlp.fc1.weight                -- torch.Size([4096, 1024])\n",
      "backbone.decoder_layers.1.blocks.6.mlp.fc1.bias                  -- torch.Size([4096])\n",
      "backbone.decoder_layers.1.blocks.6.mlp.fc2.weight                -- torch.Size([1024, 4096])\n",
      "backbone.decoder_layers.1.blocks.6.mlp.fc2.bias                  -- torch.Size([1024])\n",
      "backbone.decoder_layers.1.blocks.7.norm1.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.1.blocks.7.norm1.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.decoder_layers.1.blocks.7.attn.qkv.weight               -- torch.Size([3072, 1024])\n",
      "backbone.decoder_layers.1.blocks.7.attn.qkv.bias                 -- torch.Size([3072])\n",
      "backbone.decoder_layers.1.blocks.7.attn.proj.weight              -- torch.Size([1024, 1024])\n",
      "backbone.decoder_layers.1.blocks.7.attn.proj.bias                -- torch.Size([1024])\n",
      "backbone.decoder_layers.1.blocks.7.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 1024])\n",
      "backbone.decoder_layers.1.blocks.7.attn.lora_proj.loras.0.lora_B -- torch.Size([1024, 8])\n",
      "backbone.decoder_layers.1.blocks.7.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 1024])\n",
      "backbone.decoder_layers.1.blocks.7.attn.lora_qkv.loras.0.lora_B  -- torch.Size([3072, 8])\n",
      "backbone.decoder_layers.1.blocks.7.norm2.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.1.blocks.7.norm2.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.decoder_layers.1.blocks.7.mlp.fc1.weight                -- torch.Size([4096, 1024])\n",
      "backbone.decoder_layers.1.blocks.7.mlp.fc1.bias                  -- torch.Size([4096])\n",
      "backbone.decoder_layers.1.blocks.7.mlp.fc2.weight                -- torch.Size([1024, 4096])\n",
      "backbone.decoder_layers.1.blocks.7.mlp.fc2.bias                  -- torch.Size([1024])\n",
      "backbone.decoder_layers.1.blocks.8.norm1.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.1.blocks.8.norm1.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.decoder_layers.1.blocks.8.attn.qkv.weight               -- torch.Size([3072, 1024])\n",
      "backbone.decoder_layers.1.blocks.8.attn.qkv.bias                 -- torch.Size([3072])\n",
      "backbone.decoder_layers.1.blocks.8.attn.proj.weight              -- torch.Size([1024, 1024])\n",
      "backbone.decoder_layers.1.blocks.8.attn.proj.bias                -- torch.Size([1024])\n",
      "backbone.decoder_layers.1.blocks.8.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 1024])\n",
      "backbone.decoder_layers.1.blocks.8.attn.lora_proj.loras.0.lora_B -- torch.Size([1024, 8])\n",
      "backbone.decoder_layers.1.blocks.8.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 1024])\n",
      "backbone.decoder_layers.1.blocks.8.attn.lora_qkv.loras.0.lora_B  -- torch.Size([3072, 8])\n",
      "backbone.decoder_layers.1.blocks.8.norm2.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.1.blocks.8.norm2.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.decoder_layers.1.blocks.8.mlp.fc1.weight                -- torch.Size([4096, 1024])\n",
      "backbone.decoder_layers.1.blocks.8.mlp.fc1.bias                  -- torch.Size([4096])\n",
      "backbone.decoder_layers.1.blocks.8.mlp.fc2.weight                -- torch.Size([1024, 4096])\n",
      "backbone.decoder_layers.1.blocks.8.mlp.fc2.bias                  -- torch.Size([1024])\n",
      "backbone.decoder_layers.1.blocks.9.norm1.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.1.blocks.9.norm1.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.decoder_layers.1.blocks.9.attn.qkv.weight               -- torch.Size([3072, 1024])\n",
      "backbone.decoder_layers.1.blocks.9.attn.qkv.bias                 -- torch.Size([3072])\n",
      "backbone.decoder_layers.1.blocks.9.attn.proj.weight              -- torch.Size([1024, 1024])\n",
      "backbone.decoder_layers.1.blocks.9.attn.proj.bias                -- torch.Size([1024])\n",
      "backbone.decoder_layers.1.blocks.9.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 1024])\n",
      "backbone.decoder_layers.1.blocks.9.attn.lora_proj.loras.0.lora_B -- torch.Size([1024, 8])\n",
      "backbone.decoder_layers.1.blocks.9.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 1024])\n",
      "backbone.decoder_layers.1.blocks.9.attn.lora_qkv.loras.0.lora_B  -- torch.Size([3072, 8])\n",
      "backbone.decoder_layers.1.blocks.9.norm2.ln_modulation.1.weight  -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.1.blocks.9.norm2.ln_modulation.1.bias    -- torch.Size([2048])\n",
      "backbone.decoder_layers.1.blocks.9.mlp.fc1.weight                -- torch.Size([4096, 1024])\n",
      "backbone.decoder_layers.1.blocks.9.mlp.fc1.bias                  -- torch.Size([4096])\n",
      "backbone.decoder_layers.1.blocks.9.mlp.fc2.weight                -- torch.Size([1024, 4096])\n",
      "backbone.decoder_layers.1.blocks.9.mlp.fc2.bias                  -- torch.Size([1024])\n",
      "backbone.decoder_layers.1.upsample.lin1.weight                   -- torch.Size([2048, 1024])\n",
      "backbone.decoder_layers.1.upsample.lin2.weight                   -- torch.Size([512, 512])\n",
      "backbone.decoder_layers.1.upsample.norm.weight                   -- torch.Size([512])\n",
      "backbone.decoder_layers.1.upsample.norm.bias                     -- torch.Size([512])\n",
      "backbone.decoder_layers.2.blocks.0.norm1.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.decoder_layers.2.blocks.0.norm1.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.decoder_layers.2.blocks.0.attn.qkv.weight               -- torch.Size([1536, 512])\n",
      "backbone.decoder_layers.2.blocks.0.attn.qkv.bias                 -- torch.Size([1536])\n",
      "backbone.decoder_layers.2.blocks.0.attn.proj.weight              -- torch.Size([512, 512])\n",
      "backbone.decoder_layers.2.blocks.0.attn.proj.bias                -- torch.Size([512])\n",
      "backbone.decoder_layers.2.blocks.0.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 512])\n",
      "backbone.decoder_layers.2.blocks.0.attn.lora_proj.loras.0.lora_B -- torch.Size([512, 8])\n",
      "backbone.decoder_layers.2.blocks.0.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 512])\n",
      "backbone.decoder_layers.2.blocks.0.attn.lora_qkv.loras.0.lora_B  -- torch.Size([1536, 8])\n",
      "backbone.decoder_layers.2.blocks.0.norm2.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.decoder_layers.2.blocks.0.norm2.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.decoder_layers.2.blocks.0.mlp.fc1.weight                -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.2.blocks.0.mlp.fc1.bias                  -- torch.Size([2048])\n",
      "backbone.decoder_layers.2.blocks.0.mlp.fc2.weight                -- torch.Size([512, 2048])\n",
      "backbone.decoder_layers.2.blocks.0.mlp.fc2.bias                  -- torch.Size([512])\n",
      "backbone.decoder_layers.2.blocks.1.norm1.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.decoder_layers.2.blocks.1.norm1.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.decoder_layers.2.blocks.1.attn.qkv.weight               -- torch.Size([1536, 512])\n",
      "backbone.decoder_layers.2.blocks.1.attn.qkv.bias                 -- torch.Size([1536])\n",
      "backbone.decoder_layers.2.blocks.1.attn.proj.weight              -- torch.Size([512, 512])\n",
      "backbone.decoder_layers.2.blocks.1.attn.proj.bias                -- torch.Size([512])\n",
      "backbone.decoder_layers.2.blocks.1.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 512])\n",
      "backbone.decoder_layers.2.blocks.1.attn.lora_proj.loras.0.lora_B -- torch.Size([512, 8])\n",
      "backbone.decoder_layers.2.blocks.1.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 512])\n",
      "backbone.decoder_layers.2.blocks.1.attn.lora_qkv.loras.0.lora_B  -- torch.Size([1536, 8])\n",
      "backbone.decoder_layers.2.blocks.1.norm2.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.decoder_layers.2.blocks.1.norm2.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.decoder_layers.2.blocks.1.mlp.fc1.weight                -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.2.blocks.1.mlp.fc1.bias                  -- torch.Size([2048])\n",
      "backbone.decoder_layers.2.blocks.1.mlp.fc2.weight                -- torch.Size([512, 2048])\n",
      "backbone.decoder_layers.2.blocks.1.mlp.fc2.bias                  -- torch.Size([512])\n",
      "backbone.decoder_layers.2.blocks.2.norm1.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.decoder_layers.2.blocks.2.norm1.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.decoder_layers.2.blocks.2.attn.qkv.weight               -- torch.Size([1536, 512])\n",
      "backbone.decoder_layers.2.blocks.2.attn.qkv.bias                 -- torch.Size([1536])\n",
      "backbone.decoder_layers.2.blocks.2.attn.proj.weight              -- torch.Size([512, 512])\n",
      "backbone.decoder_layers.2.blocks.2.attn.proj.bias                -- torch.Size([512])\n",
      "backbone.decoder_layers.2.blocks.2.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 512])\n",
      "backbone.decoder_layers.2.blocks.2.attn.lora_proj.loras.0.lora_B -- torch.Size([512, 8])\n",
      "backbone.decoder_layers.2.blocks.2.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 512])\n",
      "backbone.decoder_layers.2.blocks.2.attn.lora_qkv.loras.0.lora_B  -- torch.Size([1536, 8])\n",
      "backbone.decoder_layers.2.blocks.2.norm2.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.decoder_layers.2.blocks.2.norm2.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.decoder_layers.2.blocks.2.mlp.fc1.weight                -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.2.blocks.2.mlp.fc1.bias                  -- torch.Size([2048])\n",
      "backbone.decoder_layers.2.blocks.2.mlp.fc2.weight                -- torch.Size([512, 2048])\n",
      "backbone.decoder_layers.2.blocks.2.mlp.fc2.bias                  -- torch.Size([512])\n",
      "backbone.decoder_layers.2.blocks.3.norm1.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.decoder_layers.2.blocks.3.norm1.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.decoder_layers.2.blocks.3.attn.qkv.weight               -- torch.Size([1536, 512])\n",
      "backbone.decoder_layers.2.blocks.3.attn.qkv.bias                 -- torch.Size([1536])\n",
      "backbone.decoder_layers.2.blocks.3.attn.proj.weight              -- torch.Size([512, 512])\n",
      "backbone.decoder_layers.2.blocks.3.attn.proj.bias                -- torch.Size([512])\n",
      "backbone.decoder_layers.2.blocks.3.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 512])\n",
      "backbone.decoder_layers.2.blocks.3.attn.lora_proj.loras.0.lora_B -- torch.Size([512, 8])\n",
      "backbone.decoder_layers.2.blocks.3.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 512])\n",
      "backbone.decoder_layers.2.blocks.3.attn.lora_qkv.loras.0.lora_B  -- torch.Size([1536, 8])\n",
      "backbone.decoder_layers.2.blocks.3.norm2.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.decoder_layers.2.blocks.3.norm2.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.decoder_layers.2.blocks.3.mlp.fc1.weight                -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.2.blocks.3.mlp.fc1.bias                  -- torch.Size([2048])\n",
      "backbone.decoder_layers.2.blocks.3.mlp.fc2.weight                -- torch.Size([512, 2048])\n",
      "backbone.decoder_layers.2.blocks.3.mlp.fc2.bias                  -- torch.Size([512])\n",
      "backbone.decoder_layers.2.blocks.4.norm1.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.decoder_layers.2.blocks.4.norm1.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.decoder_layers.2.blocks.4.attn.qkv.weight               -- torch.Size([1536, 512])\n",
      "backbone.decoder_layers.2.blocks.4.attn.qkv.bias                 -- torch.Size([1536])\n",
      "backbone.decoder_layers.2.blocks.4.attn.proj.weight              -- torch.Size([512, 512])\n",
      "backbone.decoder_layers.2.blocks.4.attn.proj.bias                -- torch.Size([512])\n",
      "backbone.decoder_layers.2.blocks.4.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 512])\n",
      "backbone.decoder_layers.2.blocks.4.attn.lora_proj.loras.0.lora_B -- torch.Size([512, 8])\n",
      "backbone.decoder_layers.2.blocks.4.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 512])\n",
      "backbone.decoder_layers.2.blocks.4.attn.lora_qkv.loras.0.lora_B  -- torch.Size([1536, 8])\n",
      "backbone.decoder_layers.2.blocks.4.norm2.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.decoder_layers.2.blocks.4.norm2.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.decoder_layers.2.blocks.4.mlp.fc1.weight                -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.2.blocks.4.mlp.fc1.bias                  -- torch.Size([2048])\n",
      "backbone.decoder_layers.2.blocks.4.mlp.fc2.weight                -- torch.Size([512, 2048])\n",
      "backbone.decoder_layers.2.blocks.4.mlp.fc2.bias                  -- torch.Size([512])\n",
      "backbone.decoder_layers.2.blocks.5.norm1.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.decoder_layers.2.blocks.5.norm1.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.decoder_layers.2.blocks.5.attn.qkv.weight               -- torch.Size([1536, 512])\n",
      "backbone.decoder_layers.2.blocks.5.attn.qkv.bias                 -- torch.Size([1536])\n",
      "backbone.decoder_layers.2.blocks.5.attn.proj.weight              -- torch.Size([512, 512])\n",
      "backbone.decoder_layers.2.blocks.5.attn.proj.bias                -- torch.Size([512])\n",
      "backbone.decoder_layers.2.blocks.5.attn.lora_proj.loras.0.lora_A -- torch.Size([8, 512])\n",
      "backbone.decoder_layers.2.blocks.5.attn.lora_proj.loras.0.lora_B -- torch.Size([512, 8])\n",
      "backbone.decoder_layers.2.blocks.5.attn.lora_qkv.loras.0.lora_A  -- torch.Size([8, 512])\n",
      "backbone.decoder_layers.2.blocks.5.attn.lora_qkv.loras.0.lora_B  -- torch.Size([1536, 8])\n",
      "backbone.decoder_layers.2.blocks.5.norm2.ln_modulation.1.weight  -- torch.Size([1024, 512])\n",
      "backbone.decoder_layers.2.blocks.5.norm2.ln_modulation.1.bias    -- torch.Size([1024])\n",
      "backbone.decoder_layers.2.blocks.5.mlp.fc1.weight                -- torch.Size([2048, 512])\n",
      "backbone.decoder_layers.2.blocks.5.mlp.fc1.bias                  -- torch.Size([2048])\n",
      "backbone.decoder_layers.2.blocks.5.mlp.fc2.weight                -- torch.Size([512, 2048])\n",
      "backbone.decoder_layers.2.blocks.5.mlp.fc2.bias                  -- torch.Size([512])\n",
      "decoder.level_decoder.layers.0.0.to_q.weight                     -- torch.Size([1024, 1024])\n",
      "decoder.level_decoder.layers.0.0.to_kv.weight                    -- torch.Size([2048, 1024])\n",
      "decoder.level_decoder.layers.0.0.to_out.weight                   -- torch.Size([1024, 1024])\n",
      "decoder.level_decoder.layers.0.1.net.0.weight                    -- torch.Size([2048, 1024])\n",
      "decoder.level_decoder.layers.0.1.net.0.bias                      -- torch.Size([2048])\n",
      "decoder.level_decoder.layers.0.1.net.2.weight                    -- torch.Size([1024, 2048])\n",
      "decoder.level_decoder.layers.0.1.net.2.bias                      -- torch.Size([1024])\n",
      "decoder.level_decoder.layers.0.2.weight                          -- torch.Size([1024])\n",
      "decoder.level_decoder.layers.0.2.bias                            -- torch.Size([1024])\n",
      "decoder.level_decoder.layers.0.3.weight                          -- torch.Size([1024])\n",
      "decoder.level_decoder.layers.0.3.bias                            -- torch.Size([1024])\n",
      "decoder.surf_heads.10u.weight                                    -- torch.Size([16, 1024])\n",
      "decoder.surf_heads.10u.bias                                      -- torch.Size([16])\n",
      "decoder.surf_heads.10v.weight                                    -- torch.Size([16, 1024])\n",
      "decoder.surf_heads.10v.bias                                      -- torch.Size([16])\n",
      "decoder.surf_heads.2t.weight                                     -- torch.Size([16, 1024])\n",
      "decoder.surf_heads.2t.bias                                       -- torch.Size([16])\n",
      "decoder.surf_heads.msl.weight                                    -- torch.Size([16, 1024])\n",
      "decoder.surf_heads.msl.bias                                      -- torch.Size([16])\n",
      "decoder.atmos_heads.q.weight                                     -- torch.Size([16, 1024])\n",
      "decoder.atmos_heads.q.bias                                       -- torch.Size([16])\n",
      "decoder.atmos_heads.t.weight                                     -- torch.Size([16, 1024])\n",
      "decoder.atmos_heads.t.bias                                       -- torch.Size([16])\n",
      "decoder.atmos_heads.u.weight                                     -- torch.Size([16, 1024])\n",
      "decoder.atmos_heads.u.bias                                       -- torch.Size([16])\n",
      "decoder.atmos_heads.v.weight                                     -- torch.Size([16, 1024])\n",
      "decoder.atmos_heads.v.bias                                       -- torch.Size([16])\n",
      "decoder.atmos_heads.z.weight                                     -- torch.Size([16, 1024])\n",
      "decoder.atmos_heads.z.bias                                       -- torch.Size([16])\n",
      "decoder.atmos_levels_embed.weight                                -- torch.Size([1024, 1024])\n",
      "decoder.atmos_levels_embed.bias                                  -- torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "for name,param in model.named_parameters():\n",
    "    if compress_param(name, param) or True:\n",
    "        print(f\"{name:64} -- {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8266b7a2",
   "metadata": {},
   "source": [
    "# Get total size of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e385498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Parameters: 1259150992\n",
      "Number of compressible arameters: 1238630400\n",
      "Number of uncompressible arameters: 20520592\n",
      "Compression ratio to size reductions:\n",
      "0.75 --  75.41%\n",
      "0.5 --  50.81%\n",
      "0.25 --  26.22%\n"
     ]
    }
   ],
   "source": [
    "total_cnt = 0\n",
    "compress_cnt = 0\n",
    "noncomp_cnt = 0\n",
    "for name,param in model.named_parameters():\n",
    "    n_params = np.prod(list(param.shape))\n",
    "    total_cnt += n_params\n",
    "    if compress_param(name, param):\n",
    "        compress_cnt += n_params\n",
    "    else:\n",
    "        noncomp_cnt += n_params\n",
    "\n",
    "\n",
    "print(f\"Total number of Parameters: {total_cnt}\")\n",
    "print(f\"Number of compressible arameters: {compress_cnt}\")\n",
    "print(f\"Number of uncompressible arameters: {noncomp_cnt}\")\n",
    "print(\"Compression ratio to size reductions:\")\n",
    "for ratio in [0.75, 0.5, 0.25]:\n",
    "    print(f\"{ratio} -- {100.0*(noncomp_cnt + (ratio * compress_cnt)) / total_cnt:6.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4c7d41",
   "metadata": {},
   "source": [
    "# Figure out how to use SVD to decompose data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ac4abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Aurora()\n",
    "# model.load_checkpoint(\"microsoft/aurora\", \"aurora-0.25-finetuned.ckpt\")\n",
    "model.load_checkpoint_local(\n",
    "    \"/Users/pmpaquet/Projects/Stanford/CS229S/Project/Project_aurora/models/hf_ckpt/aurora-0.25-finetuned.ckpt\"\n",
    ")\n",
    "\n",
    "for name,param in model.named_parameters():\n",
    "    if compress_param(name, param):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c5c2ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.encoder_layers.0.blocks.0.norm1.ln_modulation.1.weight torch.Size([1024, 512]) torch.Size([1024, 512]) torch.Size([512]) torch.Size([512, 512])\n"
     ]
    }
   ],
   "source": [
    "U, S, Vh = torch.linalg.svd(param.detach(), full_matrices=False)\n",
    "print(name, param.shape, U.shape, S.shape, Vh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5c1727e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 512])\n",
      "torch.Size([1024, 512])\n"
     ]
    }
   ],
   "source": [
    "print(param.shape)\n",
    "print((U[:,:64] @ torch.diag(S[:64]) @ Vh[:64]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee069ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125 64 torch.Size([1024, 64]) torch.Size([64]) torch.Size([64, 512])\n"
     ]
    }
   ],
   "source": [
    "ratio = 0.125 # greatest reduction\n",
    "k = round(S.shape[0] * ratio)\n",
    "print(ratio, k, U[:,:k].shape, S[:k].shape, Vh[:k,:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0781443",
   "metadata": {},
   "source": [
    "### See how to update the parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4844d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight torch.Size([1, 5]) Parameter containing:\n",
      "tensor([[-0.1483, -0.4368, -0.1186,  0.3334, -0.2606]], requires_grad=True)\n",
      "0.bias torch.Size([1]) Parameter containing:\n",
      "tensor([0.1484], requires_grad=True)\n",
      "\n",
      "0.weight torch.Size([1, 5]) Parameter containing:\n",
      "tensor([[0.8517, 0.5632, 0.8814, 1.3334, 0.7394]], requires_grad=True)\n",
      "0.bias torch.Size([1]) Parameter containing:\n",
      "tensor([1.1484], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(5, 1)\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for name,param in model.named_parameters():\n",
    "        print(name, param.shape, param)\n",
    "        param += 1.0\n",
    "\n",
    "print()\n",
    "\n",
    "for name,param in model.named_parameters():\n",
    "    print(name, param.shape, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e8a149ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [0, 2, 0],\n",
       "        [0, 0, 3]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(torch.tensor([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21161f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0623e04b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f27c192",
   "metadata": {},
   "source": [
    "# Compression loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a21015cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio: 0.125\n",
      "Ratio: 0.25\n",
      "Ratio: 0.5\n",
      "Ratio: 0.75\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "save_dir = Path('/Users/pmpaquet/Projects/Stanford/CS229S/Project/Project_aurora/models/svd_models')\n",
    "\n",
    "for ratio in [0.125, 0.25, 0.5, 0.75]:\n",
    "    print(\"Ratio:\", ratio)\n",
    "\n",
    "    model = Aurora()\n",
    "    model.load_checkpoint_local(\n",
    "        \"/Users/pmpaquet/Projects/Stanford/CS229S/Project/Project_aurora/models/hf_ckpt/aurora-0.25-finetuned.ckpt\"\n",
    "    )\n",
    "\n",
    "    # Update\n",
    "    with torch.no_grad():\n",
    "        for name,param in model.named_parameters():\n",
    "            if compress_param(name, param):\n",
    "                U, S, Vh = torch.linalg.svd(param.detach(), full_matrices=False)\n",
    "                k = round(S.shape[0] * ratio)\n",
    "                \n",
    "                # Apply compression\n",
    "                param = U[:,:k] @ torch.diag(S[:k]) @ Vh[:k]\n",
    "\n",
    "\n",
    "    torch.save(model.state_dict(), str(save_dir / f'aurora-0.25-finetuned-svd-{ratio}.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6e1b5706",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Aurora()\n",
    "model.load_checkpoint_local(str(save_dir / f'aurora-0.25-finetuned-svd-{ratio}.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454f22dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if this doesn't work upon inference, I can always modify the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c811f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0554e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a863aab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd27a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3347ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707558d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0dbcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
